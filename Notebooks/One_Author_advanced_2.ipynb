{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is a continuation of the One Author Advanced Project, where I will be \"manually\" cross validating and grid searching in order to find an optimal model and confirm the results of the \"One_Author_Advanced\" notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import itertools\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler\n",
    "from statistics import mean\n",
    "from scipy.sparse import hstack, csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the dataset used in the One_Author_advanced notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title_len</th>\n",
       "      <th>paper_len</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>Oral</th>\n",
       "      <th>Poster</th>\n",
       "      <th>Spotlight</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>is_bernhard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>Consistent Kernel Mean Estimation\\nfor Functio...</td>\n",
       "      <td>6545</td>\n",
       "      <td>67</td>\n",
       "      <td>33747</td>\n",
       "      <td>4.488406</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>Bayesian Experimental Design of Magnetic\\nReso...</td>\n",
       "      <td>3558</td>\n",
       "      <td>68</td>\n",
       "      <td>33280</td>\n",
       "      <td>4.916890</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>Kernel peA and De-Noising in Feature Spaces\\n\\...</td>\n",
       "      <td>1491</td>\n",
       "      <td>43</td>\n",
       "      <td>22127</td>\n",
       "      <td>4.798472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>Semiparametric Support Vector and\\nLinear Prog...</td>\n",
       "      <td>1575</td>\n",
       "      <td>61</td>\n",
       "      <td>18571</td>\n",
       "      <td>4.874520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>Minimax Estimation of Maximum Mean Discrepancy...</td>\n",
       "      <td>6483</td>\n",
       "      <td>66</td>\n",
       "      <td>29683</td>\n",
       "      <td>3.954461</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                         paper_text  paper_id  \\\n",
       "0  2016  Consistent Kernel Mean Estimation\\nfor Functio...      6545   \n",
       "1  2008  Bayesian Experimental Design of Magnetic\\nReso...      3558   \n",
       "2  1998  Kernel peA and De-Noising in Feature Spaces\\n\\...      1491   \n",
       "3  1998  Semiparametric Support Vector and\\nLinear Prog...      1575   \n",
       "4  2016  Minimax Estimation of Maximum Mean Discrepancy...      6483   \n",
       "\n",
       "   title_len  paper_len  avg_word_len  Oral  Poster  Spotlight  Unknown  \\\n",
       "0         67      33747      4.488406     0       1          0        0   \n",
       "1         68      33280      4.916890     0       0          0        1   \n",
       "2         43      22127      4.798472     0       0          0        1   \n",
       "3         61      18571      4.874520     0       0          0        1   \n",
       "4         66      29683      3.954461     0       1          0        0   \n",
       "\n",
       "   is_bernhard  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:/OtherCodeProjects/Springboard Capstone Projects/Springboard-Capstone-1-Data/one_author_advanced_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up X (features) and y (target feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['paper_id', 'is_bernhard']\n",
    "X = df[df.columns.difference(exclude)]\n",
    "\n",
    "y = df['is_bernhard'].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the other features so they are usable by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Oral</th>\n",
       "      <th>Poster</th>\n",
       "      <th>Spotlight</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>paper_len</th>\n",
       "      <th>title_len</th>\n",
       "      <th>year</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409777</td>\n",
       "      <td>0.271676</td>\n",
       "      <td>0.410596</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>Consistent Kernel Mean Estimation\\nfor Functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.477693</td>\n",
       "      <td>0.267896</td>\n",
       "      <td>0.417219</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>Bayesian Experimental Design of Magnetic\\nReso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.458923</td>\n",
       "      <td>0.177621</td>\n",
       "      <td>0.251656</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>Kernel peA and De-Noising in Feature Spaces\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.470977</td>\n",
       "      <td>0.148838</td>\n",
       "      <td>0.370861</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>Semiparametric Support Vector and\\nLinear Prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325145</td>\n",
       "      <td>0.238781</td>\n",
       "      <td>0.403974</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>Minimax Estimation of Maximum Mean Discrepancy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7234</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.422588</td>\n",
       "      <td>0.281098</td>\n",
       "      <td>0.437086</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>Linear Classification and Selective Sampling\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.510911</td>\n",
       "      <td>0.126619</td>\n",
       "      <td>0.324503</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Generalization Dynamics in\\nLMS Trained Linear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.254209</td>\n",
       "      <td>0.430464</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>MAS: a multiplicative approximation scheme for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443642</td>\n",
       "      <td>0.264076</td>\n",
       "      <td>0.198675</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>Clustering via LP-based Stabilities\\n\\nNikos K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.342712</td>\n",
       "      <td>0.249943</td>\n",
       "      <td>0.245033</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>Online Prediction on Large Diameter Graphs\\n\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7239 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Oral  Poster  Spotlight  Unknown  avg_word_len  paper_len  title_len  \\\n",
       "0      0.0     1.0        0.0      0.0      0.409777   0.271676   0.410596   \n",
       "1      0.0     0.0        0.0      1.0      0.477693   0.267896   0.417219   \n",
       "2      0.0     0.0        0.0      1.0      0.458923   0.177621   0.251656   \n",
       "3      0.0     0.0        0.0      1.0      0.470977   0.148838   0.370861   \n",
       "4      0.0     1.0        0.0      0.0      0.325145   0.238781   0.403974   \n",
       "...    ...     ...        ...      ...           ...        ...        ...   \n",
       "7234   0.0     0.0        0.0      1.0      0.422588   0.281098   0.437086   \n",
       "7235   0.0     0.0        0.0      1.0      0.510911   0.126619   0.324503   \n",
       "7236   0.0     0.0        0.0      1.0      0.436957   0.254209   0.430464   \n",
       "7237   0.0     0.0        0.0      1.0      0.443642   0.264076   0.198675   \n",
       "7238   0.0     0.0        0.0      1.0      0.342712   0.249943   0.245033   \n",
       "\n",
       "          year                                         paper_text  \n",
       "0     0.966667  Consistent Kernel Mean Estimation\\nfor Functio...  \n",
       "1     0.700000  Bayesian Experimental Design of Magnetic\\nReso...  \n",
       "2     0.366667  Kernel peA and De-Noising in Feature Spaces\\n\\...  \n",
       "3     0.366667  Semiparametric Support Vector and\\nLinear Prog...  \n",
       "4     0.966667  Minimax Estimation of Maximum Mean Discrepancy...  \n",
       "...        ...                                                ...  \n",
       "7234  0.700000  Linear Classification and Selective Sampling\\n...  \n",
       "7235  0.100000  Generalization Dynamics in\\nLMS Trained Linear...  \n",
       "7236  0.700000  MAS: a multiplicative approximation scheme for...  \n",
       "7237  0.700000  Clustering via LP-based Stabilities\\n\\nNikos K...  \n",
       "7238  0.700000  Online Prediction on Large Diameter Graphs\\n\\n...  \n",
       "\n",
       "[7239 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_feat = X[X.columns.difference(['paper_text'])]\n",
    "paper_text = pd.DataFrame(X.paper_text)\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "scaled_feat = pd.DataFrame(minmax.fit_transform(scaled_feat), columns=scaled_feat.columns)\n",
    "X = scaled_feat.join(paper_text)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Tfidf hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to check if stop words have an impact on the final model I have set up a large for loop that contains the Tfidf vectorizer and a basic logistic regression model. The default 'english' stop word set was tested agains no stop words, and the results cross validated five times across five random states for the train_test split. The final results for each model are then averaged together and saved in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_stop_words = [None, 'english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Initializing a dictionary with keys corresponding to the hyperparameters I am testing, \n",
    "# as well as my results on the train and test sets\n",
    "LR_dict = {'Tfidf_Stop_Words': [],\n",
    "            'avg_Train_auc': [],\n",
    "            'avg_Test_auc': []}\n",
    "\n",
    "run = 0\n",
    "for stop_word in Tfidf_stop_words:\n",
    "\n",
    "    # Appending the parameters for this run to my dictionary\n",
    "    LR_dict['Tfidf_Stop_Words'].append(str(stop_word))\n",
    "\n",
    "    auc_train_scores = []\n",
    "    auc_test_scores = []\n",
    "    for random_state in random_states:\n",
    "\n",
    "        # Counting what iteration I am on\n",
    "        print(run)\n",
    "        run += 1\n",
    "\n",
    "        # Initializing the TfidfVectorizer with different stop words, then .fit_transforming it on the train set\n",
    "        # and .transforming on the test set\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, train_size=0.75, stratify=y)\n",
    "\n",
    "        other_features_train = csr_matrix(X_train[X_train.columns.difference(['paper_text'])].values)\n",
    "        other_features_test = csr_matrix(X_test[X_test.columns.difference(['paper_text'])].values)\n",
    "\n",
    "        tfidf = TfidfVectorizer(stop_words=stop_word)\n",
    "\n",
    "        X_train_vector = tfidf.fit_transform(X_train.paper_text)\n",
    "        X_test_vector = tfidf.transform(X_test.paper_text)\n",
    "\n",
    "        X_train_tfidf = hstack([other_features_train, X_train_vector])\n",
    "        X_test_tfidf = hstack([other_features_test, X_test_vector])\n",
    "\n",
    "        # Making a pipeline with the logistic regressor inside, the C hyperparameter is chosen here\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('LR', LogisticRegression(class_weight='balanced', C=1, max_iter=1000)),\n",
    "            \n",
    "        ])\n",
    "\n",
    "        # Fitting the pipeline to the train set and predicting on both train and test sets\n",
    "        pipe.fit(X_train_tfidf, y_train)\n",
    "        pipe_train_pred = pipe.predict(X_train_tfidf)\n",
    "        pipe_test_pred = pipe.predict(X_test_tfidf)\n",
    "\n",
    "        # Finding the roc_auc_score for both\n",
    "        auc_train = roc_auc_score(y_train, pipe_train_pred)\n",
    "        auc_test = roc_auc_score(y_test, pipe_test_pred)\n",
    "\n",
    "        #Appending the scores to the list outside the loop\n",
    "        auc_train_scores.append(auc_train)\n",
    "        auc_test_scores.append(auc_test)\n",
    "\n",
    "    # Appending the scores to the dictionary\n",
    "    LR_dict['avg_Train_auc'].append(mean(auc_train_scores))\n",
    "    LR_dict['avg_Test_auc'].append(mean(auc_test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Tfidf inside the loop is time consuming, so I will recreate the above code without the TfidfVectorizer in the loop to test other models. Using no stop words gives better results across the models, so that is what I will use from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tfidf_Stop_Words</th>\n",
       "      <th>avg_Train_auc</th>\n",
       "      <th>avg_Test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.994798</td>\n",
       "      <td>0.749282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english</td>\n",
       "      <td>0.996991</td>\n",
       "      <td>0.726233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tfidf_Stop_Words  avg_Train_auc  avg_Test_auc\n",
       "0             None       0.994798      0.749282\n",
       "1          english       0.996991      0.726233"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_HPtable = pd.DataFrame.from_dict(LR_dict) \n",
    "tfidf_HPtable.sort_values(by='avg_Test_auc', ascending=False, inplace=True)\n",
    "tfidf_HPtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The X_train and X_test I will use to test three seperate models and their hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=16, train_size=0.75, stratify=y)\n",
    "\n",
    "other_features_train = csr_matrix(X_train[X_train.columns.difference(['paper_text'])].values)\n",
    "other_features_test = csr_matrix(X_test[X_test.columns.difference(['paper_text'])].values)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_vector = tfidf.fit_transform(X_train.paper_text)\n",
    "X_test_vector = tfidf.transform(X_test.paper_text)\n",
    "\n",
    "X_train = hstack([other_features_train, X_train_vector])\n",
    "X_test = hstack([other_features_test, X_test_vector])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first test the LogisticRegression model, with the regularization parameter (C) and the sampling of the features as my hyperparameters. I chose a range of C values from 1 down to 0.001; and the sampling being none (using class weights instead), random oversampling, and random undersampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = ['None', 'ros', 'rus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'None'),\n",
       " (1, 'ros'),\n",
       " (1, 'rus'),\n",
       " (0.5, 'None'),\n",
       " (0.5, 'ros'),\n",
       " (0.5, 'rus'),\n",
       " (0.1, 'None'),\n",
       " (0.1, 'ros'),\n",
       " (0.1, 'rus'),\n",
       " (0.05, 'None'),\n",
       " (0.05, 'ros'),\n",
       " (0.05, 'rus'),\n",
       " (0.01, 'None'),\n",
       " (0.01, 'ros'),\n",
       " (0.01, 'rus'),\n",
       " (0.005, 'None'),\n",
       " (0.005, 'ros'),\n",
       " (0.005, 'rus'),\n",
       " (0.001, 'None'),\n",
       " (0.001, 'ros'),\n",
       " (0.001, 'rus')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = list(itertools.product(\n",
    "                        C, samplers\n",
    "))\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test uses the block of code from the Tfidf test, but modified so that it tracks the F1_score and precision as well as the roc_auc, and saves the best model for each. Precision minimizes false positives, while F1_score balances between precision and recall (which minimizes false negatives). For all subsequent models I will need to choose a consistent metric to score on, and this will show me what optimizing for a particular metric looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Initializing a dictionary with keys corresponding to the hyperparameters I am testing, \n",
    "# as well as my results on the train and test sets\n",
    "LR_dict = {'LogReg_C_value' : [],\n",
    "            'Sampler': [],\n",
    "            'Precision': [],\n",
    "            'F1_score': [],\n",
    "            'Train_auc': [],\n",
    "            'Test_auc': []}\n",
    "\n",
    "run = 0\n",
    "best_score_precision = 0\n",
    "best_LR_model_precision = None\n",
    "best_score_F1 = 0\n",
    "best_LR_model_F1 = None\n",
    "best_score_auc = 0\n",
    "best_LR_model_auc = None\n",
    "\n",
    "for C_value, sampler_type in hyperparameters:\n",
    "\n",
    "    # Counting what iteration I am on\n",
    "    print(run)\n",
    "    run += 1\n",
    "    \n",
    "    # Appending the parameters for this run to my dictionary\n",
    "    LR_dict['LogReg_C_value'].append(C_value)\n",
    "    LR_dict['Sampler'].append(sampler_type)\n",
    "\n",
    "    # Making pipelines for each sampler type, with the C value used within\n",
    "    if sampler_type == 'rus':\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('rus', RandomUnderSampler(random_state=21)),\n",
    "            ('LR', LogisticRegression(C=C_value, max_iter=1000))\n",
    "            ])\n",
    "\n",
    "    elif sampler_type == 'ros':\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('ros', RandomOverSampler(random_state=21)),\n",
    "            ('LR', LogisticRegression(C=C_value, max_iter=1000))\n",
    "            ])\n",
    "\n",
    "    else:\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('LR', LogisticRegression(class_weight='balanced', C=C_value, max_iter=1000))\n",
    "            ])\n",
    "\n",
    "    # Fitting the pipeline to the train set and predicting on both train and test sets\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe_train_pred = pipe.predict(X_train)\n",
    "    pipe_test_pred = pipe.predict(X_test)\n",
    "\n",
    "    # Finding the roc_auc_score for both, I am including precision as in the past \n",
    "    # undersampling has led to awful precision scores\n",
    "    precision = precision_score(y_test, pipe_test_pred)\n",
    "    F1_score = f1_score(y_test, pipe_test_pred)\n",
    "    auc_train = roc_auc_score(y_train, pipe_train_pred)\n",
    "    auc_test = roc_auc_score(y_test, pipe_test_pred)\n",
    "\n",
    "    # Appending the scores to the dictionary\n",
    "    LR_dict['Precision'].append(precision)\n",
    "    LR_dict['F1_score'].append(F1_score)\n",
    "    LR_dict['Train_auc'].append(auc_train)\n",
    "    LR_dict['Test_auc'].append(auc_test)\n",
    "\n",
    "    # Saving the best model\n",
    "    if precision > best_score_precision:\n",
    "        best_score_precision = precision\n",
    "        best_LR_model_precision = pipe\n",
    "\n",
    "    if F1_score > best_score_F1:\n",
    "        best_score_F1 = F1_score\n",
    "        best_LR_model_F1 = pipe\n",
    "\n",
    "    if auc_test > best_score_auc:\n",
    "        best_score_auc = auc_test\n",
    "        best_LR_model_auc = pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full hyperparameter table for the LogisticRegression test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogReg_C_value</th>\n",
       "      <th>Sampler</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Train_auc</th>\n",
       "      <th>Test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.996470</td>\n",
       "      <td>0.746098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.994334</td>\n",
       "      <td>0.776233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.994148</td>\n",
       "      <td>0.775676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>None</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.990804</td>\n",
       "      <td>0.804139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.100</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.986346</td>\n",
       "      <td>0.796056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.050</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.968789</td>\n",
       "      <td>0.787974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.968696</td>\n",
       "      <td>0.787695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.050</td>\n",
       "      <td>None</td>\n",
       "      <td>0.056497</td>\n",
       "      <td>0.103627</td>\n",
       "      <td>0.938599</td>\n",
       "      <td>0.765956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>0.059361</td>\n",
       "      <td>0.860109</td>\n",
       "      <td>0.792259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>0.057895</td>\n",
       "      <td>0.867259</td>\n",
       "      <td>0.745366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.023466</td>\n",
       "      <td>0.045614</td>\n",
       "      <td>0.783935</td>\n",
       "      <td>0.755470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010</td>\n",
       "      <td>None</td>\n",
       "      <td>0.023173</td>\n",
       "      <td>0.045061</td>\n",
       "      <td>0.782078</td>\n",
       "      <td>0.753519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.500</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>0.044143</td>\n",
       "      <td>0.790346</td>\n",
       "      <td>0.750174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.005</td>\n",
       "      <td>None</td>\n",
       "      <td>0.017016</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.724768</td>\n",
       "      <td>0.696941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.640614</td>\n",
       "      <td>0.657121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.012951</td>\n",
       "      <td>0.025524</td>\n",
       "      <td>0.623894</td>\n",
       "      <td>0.640120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.050</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.023850</td>\n",
       "      <td>0.597608</td>\n",
       "      <td>0.618659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>0.591292</td>\n",
       "      <td>0.613643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>0.023314</td>\n",
       "      <td>0.589991</td>\n",
       "      <td>0.611134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.005</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>0.023314</td>\n",
       "      <td>0.589991</td>\n",
       "      <td>0.611134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>0.023314</td>\n",
       "      <td>0.589991</td>\n",
       "      <td>0.611134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LogReg_C_value Sampler  Precision  F1_score  Train_auc  Test_auc\n",
       "1            1.000     ros   0.363636  0.421053   0.996470  0.746098\n",
       "0            1.000    None   0.333333  0.418605   0.994334  0.776233\n",
       "4            0.500     ros   0.310345  0.400000   0.994148  0.775676\n",
       "3            0.500    None   0.250000  0.357143   0.990804  0.804139\n",
       "7            0.100     ros   0.144928  0.235294   0.986346  0.796056\n",
       "10           0.050     ros   0.102041  0.175439   0.968789  0.787974\n",
       "6            0.100    None   0.101010  0.173913   0.968696  0.787695\n",
       "9            0.050    None   0.056497  0.103627   0.938599  0.765956\n",
       "2            1.000     rus   0.030806  0.059361   0.860109  0.792259\n",
       "13           0.010     ros   0.030220  0.057895   0.867259  0.745366\n",
       "16           0.005     ros   0.023466  0.045614   0.783935  0.755470\n",
       "12           0.010    None   0.023173  0.045061   0.782078  0.753519\n",
       "5            0.500     rus   0.022688  0.044143   0.790346  0.750174\n",
       "15           0.005    None   0.017016  0.033333   0.724768  0.696941\n",
       "8            0.100     rus   0.013725  0.027027   0.640614  0.657121\n",
       "19           0.001     ros   0.012951  0.025524   0.623894  0.640120\n",
       "11           0.050     rus   0.012090  0.023850   0.597608  0.618659\n",
       "18           0.001    None   0.011905  0.023490   0.591292  0.613643\n",
       "14           0.010     rus   0.011814  0.023314   0.589991  0.611134\n",
       "17           0.005     rus   0.011814  0.023314   0.589991  0.611134\n",
       "20           0.001     rus   0.011814  0.023314   0.589991  0.611134"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_HPtable = pd.DataFrame.from_dict(LR_dict) \n",
    "LR_HPtable.sort_values(by='F1_score', ascending=False, inplace=True)\n",
    "LR_HPtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing for precision gets a model that has a very low number (relatively) of false positives. In this case it produced the same model as optimizing for F1_score. However, in other tests it might be too conservative a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_LR_model_precision.fit(X_train, y_train)\n",
    "best_LR_pred = best_LR_model_precision.predict(X_test)\n",
    "best_LR_cm_test = confusion_matrix(y_test, best_LR_pred)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=best_LR_cm_test)\n",
    "plt.title('Optimizing for Precision in LR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing for F1_score makes a model that balances between precision (fewer false positives) and recall (fewer false negatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_LR_model_F1.fit(X_train, y_train)\n",
    "best_LR_pred = best_LR_model_F1.predict(X_test)\n",
    "best_LR_cm_test = confusion_matrix(y_test, best_LR_pred)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=best_LR_cm_test)\n",
    "plt.title('Optimizing for F1 score in LR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting for roc_auc in this case produces a model that predicts two more papers but also greatly increases the false positive rate. This is probably too aggressive a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_LR_model_auc.fit(X_train, y_train)\n",
    "best_LR_pred = best_LR_model_auc.predict(X_test)\n",
    "best_LR_cm_test = confusion_matrix(y_test, best_LR_pred)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=best_LR_cm_test)\n",
    "plt.title('Optimizing for roc_auc in LR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use F1 score (2 * (precision * recall) / (precision + recall)) for the following models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will test the LinearSVC model, as SVC took too long to train. I am testing the same hyperparameters (C and the three different samplers) as I was with the LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = ['None', 'ros', 'rus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'None'),\n",
       " (1, 'ros'),\n",
       " (1, 'rus'),\n",
       " (0.5, 'None'),\n",
       " (0.5, 'ros'),\n",
       " (0.5, 'rus'),\n",
       " (0.1, 'None'),\n",
       " (0.1, 'ros'),\n",
       " (0.1, 'rus'),\n",
       " (0.05, 'None'),\n",
       " (0.05, 'ros'),\n",
       " (0.05, 'rus'),\n",
       " (0.01, 'None'),\n",
       " (0.01, 'ros'),\n",
       " (0.01, 'rus'),\n",
       " (0.005, 'None'),\n",
       " (0.005, 'ros'),\n",
       " (0.005, 'rus'),\n",
       " (0.001, 'None'),\n",
       " (0.001, 'ros'),\n",
       " (0.001, 'rus')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = list(itertools.product(\n",
    "                        C, samplers\n",
    "))\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Initializing a dictionary with keys corresponding to the hyperparameters I am testing, \n",
    "# as well as my results on the train and test sets\n",
    "SVC_dict = {'SVC_C_value' : [],\n",
    "            'Sampler': [],\n",
    "            'F1_score_train': [],\n",
    "            'F1_score_test': []}\n",
    "\n",
    "run = 0\n",
    "best_score_F1 = 0\n",
    "best_SVC_model = None\n",
    "\n",
    "for C_value, sampler_type in hyperparameters:\n",
    "\n",
    "    # Counting what iteration I am on\n",
    "    print(run)\n",
    "    run += 1\n",
    "    \n",
    "    # Appending the parameters for this run to my dictionary\n",
    "    SVC_dict['SVC_C_value'].append(C_value)\n",
    "    SVC_dict['Sampler'].append(sampler_type)\n",
    "\n",
    "    # Making pipelines for each sampler type, with the C value used within\n",
    "    if sampler_type == 'rus':\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('rus', RandomUnderSampler(random_state=21)),\n",
    "            ('SVC', LinearSVC(C=C_value))\n",
    "            ])\n",
    "\n",
    "    elif sampler_type == 'ros':\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('ros', RandomOverSampler(random_state=21)),\n",
    "            ('SVC', LinearSVC(C=C_value))\n",
    "            ])\n",
    "\n",
    "    else:\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('SVC', LinearSVC(class_weight='balanced', C=C_value))\n",
    "            ])\n",
    "\n",
    "    # Fitting the pipeline to the train set and predicting on both train and test sets\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe_train_pred = pipe.predict(X_train)\n",
    "    pipe_test_pred = pipe.predict(X_test)\n",
    "\n",
    "    # Finding the roc_auc_score for both, I am including precision as in the past \n",
    "    # undersampling has led to awful precision scores\n",
    "    F1_score_train = f1_score(y_train, pipe_train_pred)\n",
    "    F1_score_test = f1_score(y_test, pipe_test_pred)\n",
    "\n",
    "    # Appending the scores to the dictionary\n",
    "    SVC_dict['F1_score_train'].append(F1_score_train)\n",
    "    SVC_dict['F1_score_test'].append(F1_score_test)\n",
    "\n",
    "\n",
    "    # Saving the best model\n",
    "    if F1_score_test > best_score_F1:\n",
    "        best_score_F1 = F1_score_test\n",
    "        best_SVC_model = pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter table for the SVC model. Overall it looks pretty similar to the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVC_C_value</th>\n",
       "      <th>Sampler</th>\n",
       "      <th>F1_score_train</th>\n",
       "      <th>F1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.100</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.844037</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.050</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.989247</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>None</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.050</td>\n",
       "      <td>None</td>\n",
       "      <td>0.519774</td>\n",
       "      <td>0.377358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.298013</td>\n",
       "      <td>0.180180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010</td>\n",
       "      <td>None</td>\n",
       "      <td>0.298013</td>\n",
       "      <td>0.176991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.143079</td>\n",
       "      <td>0.105691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.005</td>\n",
       "      <td>None</td>\n",
       "      <td>0.162264</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.500</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.131429</td>\n",
       "      <td>0.101167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.071930</td>\n",
       "      <td>0.058394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.063235</td>\n",
       "      <td>0.054852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>0.039715</td>\n",
       "      <td>0.037901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.050</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.010</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.021196</td>\n",
       "      <td>0.023314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.005</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.021196</td>\n",
       "      <td>0.023314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.001</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>0.023295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SVC_C_value Sampler  F1_score_train  F1_score_test\n",
       "7         0.100     ros        0.844037       0.484848\n",
       "6         0.100    None        0.671533       0.473684\n",
       "10        0.050     ros        0.671533       0.461538\n",
       "1         1.000     ros        0.989247       0.454545\n",
       "0         1.000    None        0.958333       0.454545\n",
       "4         0.500     ros        0.958333       0.454545\n",
       "3         0.500    None        0.920000       0.416667\n",
       "9         0.050    None        0.519774       0.377358\n",
       "13        0.010     ros        0.396552       0.250000\n",
       "16        0.005     ros        0.298013       0.180180\n",
       "12        0.010    None        0.298013       0.176991\n",
       "2         1.000     rus        0.143079       0.105691\n",
       "15        0.005    None        0.162264       0.102564\n",
       "5         0.500     rus        0.131429       0.101167\n",
       "19        0.001     ros        0.071930       0.058394\n",
       "8         0.100     rus        0.063235       0.054852\n",
       "18        0.001    None        0.039715       0.037901\n",
       "11        0.050     rus        0.036364       0.034483\n",
       "14        0.010     rus        0.021196       0.023314\n",
       "17        0.005     rus        0.021196       0.023314\n",
       "20        0.001     rus        0.021167       0.023295"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_HPtable = pd.DataFrame.from_dict(SVC_dict) \n",
    "SVC_HPtable.sort_values(by='F1_score_test', ascending=False, inplace=True)\n",
    "SVC_HPtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_SVC_model.fit(X_train, y_train)\n",
    "best_SVC_pred = best_SVC_model.predict(X_test)\n",
    "best_SVC_cm_test = confusion_matrix(y_test, best_SVC_pred)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=best_SVC_cm_test)\n",
    "plt.title('Best SVC Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm testing a Random Forest Classifier. Here the hyperparameters are n_estimators (the number of 'trees' in the forest), and the same samplers as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(n) for n in np.logspace(start=2, stop=3, num=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = ['None', 'ros', 'rus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100, 'None'),\n",
       " (100, 'ros'),\n",
       " (100, 'rus'),\n",
       " (177, 'None'),\n",
       " (177, 'ros'),\n",
       " (177, 'rus'),\n",
       " (316, 'None'),\n",
       " (316, 'ros'),\n",
       " (316, 'rus'),\n",
       " (562, 'None'),\n",
       " (562, 'ros'),\n",
       " (562, 'rus'),\n",
       " (1000, 'None'),\n",
       " (1000, 'ros'),\n",
       " (1000, 'rus')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = list(itertools.product(\n",
    "                        n_estimators, samplers\n",
    "))\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# Initializing a dictionary with keys corresponding to the hyperparameters I am testing, \n",
    "# as well as my results on the train and test sets\n",
    "RFC_dict = {'n_estimators': [],\n",
    "            'Sampler': [],\n",
    "            'F1_score_train': [],\n",
    "            'F1_score_test': []}\n",
    "\n",
    "run = 0\n",
    "best_score_F1 = 0\n",
    "best_RFC_model = None\n",
    "\n",
    "for n_estimator, sampler_type in hyperparameters:\n",
    "\n",
    "    # Counting what iteration I am on\n",
    "    print(run)\n",
    "    run += 1\n",
    "    \n",
    "    # Appending the parameters for this run to my dictionary\n",
    "    RFC_dict['Sampler'].append(sampler_type)\n",
    "    RFC_dict['n_estimators'].append(n_estimator)\n",
    "\n",
    "    # Making pipelines for each sampler type, with the n_estimator value used within\n",
    "    if sampler_type == 'rus':\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('rus', RandomUnderSampler(random_state=21)),\n",
    "            ('RFC', RandomForestClassifier(n_estimators=n_estimator, max_leaf_nodes=2000, min_samples_leaf=3, max_depth=50))\n",
    "            ])\n",
    "\n",
    "    elif sampler_type == 'ros':\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('ros', RandomOverSampler(random_state=21)),\n",
    "            ('RFC', RandomForestClassifier(n_estimators=n_estimator, max_leaf_nodes=2000, min_samples_leaf=3, max_depth=50))\n",
    "            ])\n",
    "\n",
    "    else:\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('RFC', RandomForestClassifier(n_estimators=n_estimator, class_weight=\"balanced_subsample\", max_leaf_nodes=2000, min_samples_leaf=3))\n",
    "            ])\n",
    "\n",
    "    # Fitting the pipeline to the train set and predicting on both train and test sets\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe_train_pred = pipe.predict(X_train)\n",
    "    pipe_test_pred = pipe.predict(X_test)\n",
    "\n",
    "    # Finding the roc_auc_score for both, I am including precision as in the past \n",
    "    # undersampling has led to awful precision scores\n",
    "    F1_score_train = f1_score(y_train, pipe_train_pred)\n",
    "    F1_score_test = f1_score(y_test, pipe_test_pred)\n",
    "\n",
    "    # Appending the scores to the dictionary\n",
    "    RFC_dict['F1_score_train'].append(F1_score_train)\n",
    "    RFC_dict['F1_score_test'].append(F1_score_test)\n",
    "\n",
    "\n",
    "    # Saving the best model\n",
    "    if F1_score_test > best_score_F1:\n",
    "        best_score_F1 = F1_score_test\n",
    "        best_RFC_model = pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>Sampler</th>\n",
       "      <th>F1_score_train</th>\n",
       "      <th>F1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>316</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.263610</td>\n",
       "      <td>0.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.248649</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>562</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.246649</td>\n",
       "      <td>0.178082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>177</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.193277</td>\n",
       "      <td>0.132597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>rus</td>\n",
       "      <td>0.143079</td>\n",
       "      <td>0.114286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>ros</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177</td>\n",
       "      <td>ros</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>316</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>316</td>\n",
       "      <td>ros</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>562</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>562</td>\n",
       "      <td>ros</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000</td>\n",
       "      <td>ros</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators Sampler  F1_score_train  F1_score_test\n",
       "8            316     rus        0.263610       0.212121\n",
       "14          1000     rus        0.248649       0.190476\n",
       "11           562     rus        0.246649       0.178082\n",
       "5            177     rus        0.193277       0.132597\n",
       "2            100     rus        0.143079       0.114286\n",
       "0            100    None        1.000000       0.000000\n",
       "1            100     ros        1.000000       0.000000\n",
       "3            177    None        1.000000       0.000000\n",
       "4            177     ros        1.000000       0.000000\n",
       "6            316    None        1.000000       0.000000\n",
       "7            316     ros        1.000000       0.000000\n",
       "9            562    None        1.000000       0.000000\n",
       "10           562     ros        1.000000       0.000000\n",
       "12          1000    None        1.000000       0.000000\n",
       "13          1000     ros        1.000000       0.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_HPtable = pd.DataFrame.from_dict(RFC_dict) \n",
    "RFC_HPtable.sort_values(by='F1_score_test', ascending=False, inplace=True)\n",
    "RFC_HPtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_RFC_model.fit(X_train, y_train)\n",
    "best_RFC_pred = best_RFC_model.predict(X_test)\n",
    "best_RFC_cm_test = confusion_matrix(y_test, best_RFC_pred)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=best_RFC_cm_test)\n",
    "plt.title('Best RFC Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trying truncatedSVD analysis on LR model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=16, train_size=0.75, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This paper messed with the SVD analysis, having PCA1 and PCA2 scores 100s of times higher than the others. All I can see is that it is the longest paper by ~10x and contains a lot of newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oral                                                          0.0\n",
       "Poster                                                        1.0\n",
       "Spotlight                                                     0.0\n",
       "Unknown                                                       0.0\n",
       "avg_word_len                                             0.527825\n",
       "paper_len                                                0.237964\n",
       "title_len                                                0.470199\n",
       "year                                                     0.966667\n",
       "paper_text      Learning shape correspondence with\\nanisotropi...\n",
       "Name: 652, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[982]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title_len</th>\n",
       "      <th>paper_len</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>Oral</th>\n",
       "      <th>Poster</th>\n",
       "      <th>Spotlight</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>is_bernhard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>2016</td>\n",
       "      <td>Learning Multiagent Communication\\nwith Backpr...</td>\n",
       "      <td>6398</td>\n",
       "      <td>54</td>\n",
       "      <td>123727</td>\n",
       "      <td>4.553913</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>2013</td>\n",
       "      <td>On the Representational Efficiency of Restrict...</td>\n",
       "      <td>5020</td>\n",
       "      <td>67</td>\n",
       "      <td>67731</td>\n",
       "      <td>4.215039</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>2013</td>\n",
       "      <td>A Stability-based Validation Procedure for\\nDi...</td>\n",
       "      <td>5014</td>\n",
       "      <td>82</td>\n",
       "      <td>61615</td>\n",
       "      <td>4.019754</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>1987</td>\n",
       "      <td>317\\n\\nPARTITIONING OF SENSORY DATA BY A CORTI...</td>\n",
       "      <td>44</td>\n",
       "      <td>50</td>\n",
       "      <td>58011</td>\n",
       "      <td>5.471569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>2017</td>\n",
       "      <td>A Unified Game-Theoretic Approach to\\nMultiage...</td>\n",
       "      <td>7007</td>\n",
       "      <td>70</td>\n",
       "      <td>56172</td>\n",
       "      <td>5.534487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                                         paper_text  paper_id  \\\n",
       "2777  2016  Learning Multiagent Communication\\nwith Backpr...      6398   \n",
       "1540  2013  On the Representational Efficiency of Restrict...      5020   \n",
       "1559  2013  A Stability-based Validation Procedure for\\nDi...      5014   \n",
       "5989  1987  317\\n\\nPARTITIONING OF SENSORY DATA BY A CORTI...        44   \n",
       "1764  2017  A Unified Game-Theoretic Approach to\\nMultiage...      7007   \n",
       "\n",
       "      title_len  paper_len  avg_word_len  Oral  Poster  Spotlight  Unknown  \\\n",
       "2777         54     123727      4.553913     0       1          0        0   \n",
       "1540         67      67731      4.215039     0       1          0        0   \n",
       "1559         82      61615      4.019754     0       1          0        0   \n",
       "5989         50      58011      5.471569     0       0          0        1   \n",
       "1764         70      56172      5.534487     0       1          0        0   \n",
       "\n",
       "      is_bernhard  \n",
       "2777            0  \n",
       "1540            0  \n",
       "1559            0  \n",
       "5989            0  \n",
       "1764            0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df= df.sort_values(by='paper_len', ascending=False).head()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=16, train_size=0.75, stratify=y)\n",
    "\n",
    "other_features_train = csr_matrix(X_train[X_train.columns.difference(['paper_text'])].values)\n",
    "other_features_test = csr_matrix(X_test[X_test.columns.difference(['paper_text'])].values)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_vector = tfidf.fit_transform(X_train.paper_text)\n",
    "X_test_vector = tfidf.transform(X_test.paper_text)\n",
    "\n",
    "X_train = hstack([other_features_train, X_train_vector])\n",
    "X_test = hstack([other_features_test, X_test_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "X_train = standard_scaler.fit_transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSVD = TruncatedSVD(n_components=2, random_state=21)\n",
    "\n",
    "X_train = tSVD.fit_transform(X_train)\n",
    "X_test = tSVD.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCAdf = pd.DataFrame(data=X_train, columns = ['PC1', 'PC2'])\n",
    "y_df = pd.DataFrame(data=y_train, columns=['is_bernhard'])\n",
    "\n",
    "PCAdf = pd.concat([PCAdf, y_df], axis = 1)\n",
    "PCAdf.sort_values(by='is_bernhard', ascending=True, inplace=True)\n",
    "PCAdf2 = PCAdf.drop(982)\n",
    "PCAdf2.sort_values(by='is_bernhard', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = PCAdf.PC1\n",
    "y_axis = PCAdf.PC2\n",
    "\n",
    "plt.subplots()\n",
    "sns.scatterplot(x=x_axis, y=y_axis, hue=PCAdf.is_bernhard, data=PCAdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = PCAdf2.PC1\n",
    "y_axis = PCAdf2.PC2\n",
    "\n",
    "plt.subplots()\n",
    "sns.scatterplot(x=x_axis, y=y_axis, hue=PCAdf2.is_bernhard, data=PCAdf2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing what TruncatedSVD does to the LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=16, train_size=0.75, stratify=y)\n",
    "\n",
    "other_features_train = csr_matrix(X_train[X_train.columns.difference(['paper_text'])].values)\n",
    "other_features_test = csr_matrix(X_test[X_test.columns.difference(['paper_text'])].values)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_vector = tfidf.fit_transform(X_train.paper_text)\n",
    "X_test_vector = tfidf.transform(X_test.paper_text)\n",
    "\n",
    "X_train = hstack([other_features_train, X_train_vector])\n",
    "X_test = hstack([other_features_test, X_test_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "X_train = standard_scaler.fit_transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = [2, 10, 50, 100, 300, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Initializing a dictionary with keys corresponding to the hyperparameters I am testing, \n",
    "# as well as my results on the train and test sets\n",
    "SVD_dict = {'n_components' : [],\n",
    "            'F1_score_train': [],\n",
    "            'F1_score_test': []}\n",
    "\n",
    "run = 0\n",
    "best_score_F1 = 0\n",
    "best_SVD_model = None\n",
    "\n",
    "for n_component in n_components:\n",
    "\n",
    "    # Counting what iteration I am on\n",
    "    print(run)\n",
    "    run += 1\n",
    "    \n",
    "    # Appending the parameters for this run to my dictionary\n",
    "    SVD_dict['n_components'].append(n_component)\n",
    "\n",
    "    # Making pipelines for each n_component\n",
    "    tSVD = TruncatedSVD(n_components=n_component)\n",
    "\n",
    "    X_train_SVD = tSVD.fit_transform(X_train)\n",
    "    X_test_SVD = tSVD.transform(X_test)\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "            ('LR', LogisticRegression(class_weight='balanced', C=0.5, max_iter=2000))\n",
    "            ])\n",
    "\n",
    "    # Fitting the pipeline to the train set and predicting on both train and test sets\n",
    "    pipe.fit(X_train_SVD, y_train)\n",
    "    pipe_train_pred = pipe.predict(X_train_SVD)\n",
    "    pipe_test_pred = pipe.predict(X_test_SVD)\n",
    "\n",
    "    # Finding the roc_auc_score for both, I am including precision as in the past \n",
    "    # undersampling has led to awful precision scores\n",
    "    F1_score_train = f1_score(y_train, pipe_train_pred)\n",
    "    F1_score_test = f1_score(y_test, pipe_test_pred)\n",
    "\n",
    "    # Appending the scores to the dictionary\n",
    "    SVD_dict['F1_score_train'].append(F1_score_train)\n",
    "    SVD_dict['F1_score_test'].append(F1_score_test)\n",
    "\n",
    "    # Saving the best model\n",
    "    if F1_score_test > best_score_F1:\n",
    "        best_score_F1 = F1_score_test\n",
    "        best_SVD_model = pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>F1_score_train</th>\n",
       "      <th>F1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>0.248649</td>\n",
       "      <td>0.212766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>0.544379</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.103165</td>\n",
       "      <td>0.088889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.054608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.027003</td>\n",
       "      <td>0.028450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.025907</td>\n",
       "      <td>0.026634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_components  F1_score_train  F1_score_test\n",
       "6          1000        1.000000       0.272727\n",
       "4           300        0.248649       0.212766\n",
       "5           500        0.544379       0.166667\n",
       "3           100        0.103165       0.088889\n",
       "2            50        0.056818       0.054608\n",
       "1            10        0.027003       0.028450\n",
       "0             2        0.025907       0.026634"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVD_HPtable = pd.DataFrame.from_dict(SVD_dict) \n",
    "SVD_HPtable.sort_values(by='F1_score_test', ascending=False, inplace=True)\n",
    "SVD_HPtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tSVD = TruncatedSVD(n_components=1000)\n",
    "\n",
    "X_train_SVD = tSVD.fit_transform(X_train)\n",
    "X_test_SVD = tSVD.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_SVD_model.fit(X_train_SVD, y_train)\n",
    "best_SVD_pred = best_SVD_model.predict(X_test_SVD)\n",
    "SVD_test = confusion_matrix(y_test, best_SVD_pred)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=SVD_test)\n",
    "plt.title('Linear Regression + SVD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [1, 0.5, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = ['None', 'ros']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'None'),\n",
       " (1, 'ros'),\n",
       " (0.5, 'None'),\n",
       " (0.5, 'ros'),\n",
       " (0.1, 'None'),\n",
       " (0.1, 'ros')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = list(itertools.product(\n",
    "                        C, samplers\n",
    "))\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Initializing a dictionary with keys corresponding to the hyperparameters I am testing, \n",
    "# as well as my results on the train and test sets\n",
    "LR_dict_final = {'LogReg_C_value' : [],\n",
    "            'Sampler': [],\n",
    "            'F1_score_train_avg': [],\n",
    "            'F1_score_test_avg':[]}\n",
    "\n",
    "run = 0\n",
    "\n",
    "for C_value, sampler_type in hyperparameters:\n",
    "\n",
    "    # Counting what iteration I am on\n",
    "    print(run)\n",
    "    run += 1\n",
    "    \n",
    "    # Appending the parameters for this run to my dictionary\n",
    "    LR_dict_final['LogReg_C_value'].append(C_value)\n",
    "    LR_dict_final['Sampler'].append(sampler_type)\n",
    "\n",
    "    F1_train_scores = []\n",
    "    F1_test_scores = []\n",
    "    for random_state in random_states:\n",
    "\n",
    "        # For each random state create a new train/test split and re-TfidfVectorize\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, train_size=0.75, stratify=y)\n",
    "\n",
    "        other_features_train = csr_matrix(X_train[X_train.columns.difference(['paper_text'])].values)\n",
    "        other_features_test = csr_matrix(X_test[X_test.columns.difference(['paper_text'])].values)\n",
    "\n",
    "        tfidf = TfidfVectorizer()\n",
    "\n",
    "        X_train_vector = tfidf.fit_transform(X_train.paper_text)\n",
    "        X_test_vector = tfidf.transform(X_test.paper_text)\n",
    "\n",
    "        X_train = hstack([other_features_train, X_train_vector])\n",
    "        X_test = hstack([other_features_test, X_test_vector])\n",
    "\n",
    "        # Making pipelines for each sampler type, with the C value used within\n",
    "        if sampler_type == 'ros':\n",
    "            pipe = Pipeline(steps=[\n",
    "                ('ros', RandomOverSampler(random_state=21)),\n",
    "                ('LR', LogisticRegression(C=C_value, max_iter = 1000))\n",
    "                ])\n",
    "\n",
    "        else:\n",
    "            pipe = Pipeline(steps=[\n",
    "                ('LR', LogisticRegression(class_weight='balanced', C=C_value, max_iter = 1000))\n",
    "                ])\n",
    "\n",
    "        # Fitting the pipeline to the train set and predicting on both train and test sets\n",
    "        pipe.fit(X_train, y_train)\n",
    "        pipe_train_pred = pipe.predict(X_train)\n",
    "        pipe_test_pred = pipe.predict(X_test)\n",
    "\n",
    "        # Finding the roc_auc_score for both, I am including precision as in the past \n",
    "        # undersampling has led to awful precision scores\n",
    "        F1_score_train = f1_score(y_train, pipe_train_pred)\n",
    "        F1_score_test = f1_score(y_test, pipe_test_pred)\n",
    "\n",
    "        #Appending the scores to the list outside the loop\n",
    "        F1_train_scores.append(F1_score_train)\n",
    "        F1_test_scores.append(F1_score_test)\n",
    "        \n",
    "    # Appending the scores to the dictionary\n",
    "    LR_dict_final['F1_score_train_avg'].append(mean(F1_train_scores))\n",
    "    LR_dict_final['F1_score_test_avg'].append(mean(F1_test_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogReg_C_value</th>\n",
       "      <th>Sampler</th>\n",
       "      <th>F1_score_train_avg</th>\n",
       "      <th>F1_score_test_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.736420</td>\n",
       "      <td>0.400422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.618118</td>\n",
       "      <td>0.342637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.622429</td>\n",
       "      <td>0.335779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>0.516402</td>\n",
       "      <td>0.292493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.395816</td>\n",
       "      <td>0.239398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>0.312448</td>\n",
       "      <td>0.198353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LogReg_C_value Sampler  F1_score_train_avg  F1_score_test_avg\n",
       "1             1.0     ros            0.736420           0.400422\n",
       "3             0.5     ros            0.618118           0.342637\n",
       "0             1.0    None            0.622429           0.335779\n",
       "2             0.5    None            0.516402           0.292493\n",
       "5             0.1     ros            0.395816           0.239398\n",
       "4             0.1    None            0.312448           0.198353"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_final_HPtable = pd.DataFrame.from_dict(LR_dict_final) \n",
    "LR_final_HPtable.sort_values(by='F1_score_test_avg', ascending=False, inplace=True)\n",
    "LR_final_HPtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validating the SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [1, 0.5, 0.1, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = ['None', 'ros']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'None'),\n",
       " (1, 'ros'),\n",
       " (0.5, 'None'),\n",
       " (0.5, 'ros'),\n",
       " (0.1, 'None'),\n",
       " (0.1, 'ros'),\n",
       " (0.05, 'None'),\n",
       " (0.05, 'ros')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters = list(itertools.product(\n",
    "                        C, samplers\n",
    "))\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Initializing a dictionary with keys corresponding to the hyperparameters I am testing, \n",
    "# as well as my results on the train and test sets\n",
    "SVC_dict_final = {'SVC_C_value' : [],\n",
    "            'Sampler': [],\n",
    "            'F1_score_train_avg': [],\n",
    "            'F1_score_test_avg':[]}\n",
    "\n",
    "run = 0\n",
    "\n",
    "for C_value, sampler_type in hyperparameters:\n",
    "\n",
    "    # Counting what iteration I am on\n",
    "    print(run)\n",
    "    run += 1\n",
    "    \n",
    "    # Appending the parameters for this run to my dictionary\n",
    "    SVC_dict_final['SVC_C_value'].append(C_value)\n",
    "    SVC_dict_final['Sampler'].append(sampler_type)\n",
    "\n",
    "    F1_train_scores = []\n",
    "    F1_test_scores = []\n",
    "    for random_state in random_states:\n",
    "\n",
    "        # For each random state create a new train/test split and re-TfidfVectorize\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, train_size=0.75, stratify=y)\n",
    "\n",
    "        other_features_train = csr_matrix(X_train[X_train.columns.difference(['paper_text'])].values)\n",
    "        other_features_test = csr_matrix(X_test[X_test.columns.difference(['paper_text'])].values)\n",
    "\n",
    "        tfidf = TfidfVectorizer()\n",
    "\n",
    "        X_train_vector = tfidf.fit_transform(X_train.paper_text)\n",
    "        X_test_vector = tfidf.transform(X_test.paper_text)\n",
    "\n",
    "        X_train = hstack([other_features_train, X_train_vector])\n",
    "        X_test = hstack([other_features_test, X_test_vector])\n",
    "\n",
    "        # Making pipelines for each sampler type, with the C value used within\n",
    "        if sampler_type == 'ros':\n",
    "            pipe = Pipeline(steps=[\n",
    "                ('ros', RandomOverSampler(random_state=21)),\n",
    "                ('SVC', LinearSVC(C=C_value))\n",
    "                ])\n",
    "\n",
    "        else:\n",
    "            pipe = Pipeline(steps=[\n",
    "                ('SVC', LinearSVC(class_weight='balanced', C=C_value, max_iter = 1000))\n",
    "                ])\n",
    "\n",
    "        # Fitting the pipeline to the train set and predicting on both train and test sets\n",
    "        pipe.fit(X_train, y_train)\n",
    "        pipe_train_pred = pipe.predict(X_train)\n",
    "        pipe_test_pred = pipe.predict(X_test)\n",
    "\n",
    "        # Finding the roc_auc_score for both, I am including precision as in the past \n",
    "        # undersampling has led to awful precision scores\n",
    "        F1_score_train = f1_score(y_train, pipe_train_pred)\n",
    "        F1_score_test = f1_score(y_test, pipe_test_pred)\n",
    "\n",
    "        #Appending the scores to the list outside the loop\n",
    "        F1_train_scores.append(F1_score_train)\n",
    "        F1_test_scores.append(F1_score_test)\n",
    "        \n",
    "    # Appending the scores to the dictionary\n",
    "    SVC_dict_final['F1_score_train_avg'].append(mean(F1_train_scores))\n",
    "    SVC_dict_final['F1_score_test_avg'].append(mean(F1_test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVC_C_value</th>\n",
       "      <th>Sampler</th>\n",
       "      <th>F1_score_train_avg</th>\n",
       "      <th>F1_score_test_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>None</td>\n",
       "      <td>0.937070</td>\n",
       "      <td>0.465373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.817270</td>\n",
       "      <td>0.439944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>None</td>\n",
       "      <td>0.983023</td>\n",
       "      <td>0.436330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.980872</td>\n",
       "      <td>0.436330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.676678</td>\n",
       "      <td>0.393547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.05</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.674759</td>\n",
       "      <td>0.391808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>ros</td>\n",
       "      <td>0.995699</td>\n",
       "      <td>0.374433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.05</td>\n",
       "      <td>None</td>\n",
       "      <td>0.539322</td>\n",
       "      <td>0.324028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SVC_C_value Sampler  F1_score_train_avg  F1_score_test_avg\n",
       "2         0.50    None            0.937070           0.465373\n",
       "5         0.10     ros            0.817270           0.439944\n",
       "0         1.00    None            0.983023           0.436330\n",
       "3         0.50     ros            0.980872           0.436330\n",
       "4         0.10    None            0.676678           0.393547\n",
       "7         0.05     ros            0.674759           0.391808\n",
       "1         1.00     ros            0.995699           0.374433\n",
       "6         0.05    None            0.539322           0.324028"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_final_HPtable = pd.DataFrame.from_dict(SVC_dict_final) \n",
    "SVC_final_HPtable.sort_values(by='F1_score_test_avg', ascending=False, inplace=True)\n",
    "SVC_final_HPtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking feature importance in optimal pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=16, train_size=0.75, stratify=y)\n",
    "\n",
    "other_features_train = csr_matrix(X_train[X_train.columns.difference(['paper_text'])].values)\n",
    "other_features_test = csr_matrix(X_test[X_test.columns.difference(['paper_text'])].values)\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=None)\n",
    "\n",
    "X_train_vector = tfidf.fit_transform(X_train.paper_text)\n",
    "X_test_vector = tfidf.transform(X_test.paper_text)\n",
    "\n",
    "X_train = hstack([other_features_train, X_train_vector])\n",
    "X_test = hstack([other_features_test, X_test_vector])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "                ('SVC', LinearSVC(C=0.5, class_weight='balanced', max_iter=1000))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "pipe_train_pred = pipe.predict(X_train)\n",
    "pipe_test_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n",
      "0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "F1_score_train = f1_score(y_train, pipe_train_pred)\n",
    "F1_score_test = f1_score(y_test, pipe_test_pred)\n",
    "print(F1_score_train)\n",
    "print(F1_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Final_test = confusion_matrix(y_test, pipe_test_pred)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=Final_test)\n",
    "plt.title('Final SVC Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3960/1857186089.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipe_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mneg_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe_predict_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe_predict_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpos_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe_predict_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe_predict_proba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;31m# delegate only on instances, not the classes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;31m# this is to allow access to the docstrings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mattr_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMethodType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mcheck\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# raise original `AttributeError` if `attr` does not exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "pipe_predict_proba = pipe.predict_proba(X_test)\n",
    "\n",
    "neg_weights = 100 * np.ones_like(pipe_predict_proba[:, 1][y_test==0]) / len(pipe_predict_proba[:, 1][y_test==0])\n",
    "pos_weights = 100 * np.ones_like(pipe_predict_proba[:, 1][y_test==1]) / len(pipe_predict_proba[:, 1][y_test==1])\n",
    "\n",
    "plt.hist(pipe_predict_proba[:, 1][y_test==0], color='Red', alpha=0.5, label='True Negatives', bins=50, weights=neg_weights)\n",
    "plt.hist(pipe_predict_proba[:, 1][y_test==1], color='Blue', alpha=0.5, label='True Positives', bins=20, weights=pos_weights)\n",
    "plt.xlabel('Probability of being Positive Class')\n",
    "plt.ylabel('Percent of Dataset in Bin')\n",
    "plt.title('Probability a Paper is Bernhard Scholkopf\\'s')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Oral', 'Poster', 'Spotlight', 'Unknown', 'avg_word_len', 'paper_len']\n",
    "for feature_name in tfidf.get_feature_names_out():\n",
    "    columns.append(feature_name)\n",
    "columns.append('title_len')\n",
    "columns.append('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177684</th>\n",
       "      <td>tq1</td>\n",
       "      <td>1.637397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98262</th>\n",
       "      <td>ipglon</td>\n",
       "      <td>1.550710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165133</th>\n",
       "      <td>smola2</td>\n",
       "      <td>1.488218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91345</th>\n",
       "      <td>hypergrid</td>\n",
       "      <td>1.469599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159712</th>\n",
       "      <td>scholkopj</td>\n",
       "      <td>1.460791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143386</th>\n",
       "      <td>posterior3</td>\n",
       "      <td>-0.557924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78031</th>\n",
       "      <td>for111</td>\n",
       "      <td>-0.568376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55337</th>\n",
       "      <td>convexconcave</td>\n",
       "      <td>-0.626062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175929</th>\n",
       "      <td>time10</td>\n",
       "      <td>-0.643536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avg_word_len</td>\n",
       "      <td>-0.845220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197410 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature     value\n",
       "177684            tq1  1.637397\n",
       "98262          ipglon  1.550710\n",
       "165133         smola2  1.488218\n",
       "91345       hypergrid  1.469599\n",
       "159712      scholkopj  1.460791\n",
       "...               ...       ...\n",
       "143386     posterior3 -0.557924\n",
       "78031          for111 -0.568376\n",
       "55337   convexconcave -0.626062\n",
       "175929         time10 -0.643536\n",
       "4        avg_word_len -0.845220\n",
       "\n",
       "[197410 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp_df = pd.DataFrame(pipe.named_steps['SVC'].coef_, columns=columns)\n",
    "feature_imp_df = feature_imp_df.T.reset_index().rename(columns={0:'value', 'index':'feature'})\n",
    "feature_imp_df.sort_values(by='value', ascending=False, inplace=True)\n",
    "feature_imp_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Springboard_Capstone_1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "918dc82fcda072602f7dedc1715dd52bd51c73a6bbc48592bc491021bad55eb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
