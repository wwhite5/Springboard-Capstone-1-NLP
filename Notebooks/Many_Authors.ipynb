{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import hamming_loss, f1_score\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>title_len</th>\n",
       "      <th>paper_len</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>Oral</th>\n",
       "      <th>Poster</th>\n",
       "      <th>Spotlight</th>\n",
       "      <th>Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>21643</td>\n",
       "      <td>4.808264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>21643</td>\n",
       "      <td>4.808264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>98</td>\n",
       "      <td>15505</td>\n",
       "      <td>4.886807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "      <td>100</td>\n",
       "      <td>155</td>\n",
       "      <td>116</td>\n",
       "      <td>20523</td>\n",
       "      <td>5.784861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "      <td>100</td>\n",
       "      <td>54</td>\n",
       "      <td>116</td>\n",
       "      <td>20523</td>\n",
       "      <td>5.784861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                         paper_text  paper_id  \\\n",
       "0  1987  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...         1   \n",
       "1  1987  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...         1   \n",
       "2  1987  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...        10   \n",
       "3  1988  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...       100   \n",
       "4  1988  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...       100   \n",
       "\n",
       "   author_id  title_len  paper_len  avg_word_len  Oral  Poster  Spotlight  \\\n",
       "0          1         62      21643      4.808264     0       0          0   \n",
       "1          2         62      21643      4.808264     0       0          0   \n",
       "2         14         98      15505      4.886807     0       0          0   \n",
       "3        155        116      20523      5.784861     0       0          0   \n",
       "4         54        116      20523      5.784861     0       0          0   \n",
       "\n",
       "   Unknown  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_and_authors = pd.read_csv('E:/OtherCodeProjects/Springboard Capstone Projects/Springboard-Capstone-1-Data/added_features_data.csv')\n",
    "papers_and_authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>paper_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>330</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1472</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id  paper_count\n",
       "0        330          101\n",
       "1       1472           62\n",
       "2        178           60\n",
       "3        121           58\n",
       "4       1020           51"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_authors = papers_and_authors.groupby(by='author_id')['paper_id'].count().sort_values(ascending=False).to_frame()\n",
    "top_authors.reset_index(inplace=True)\n",
    "top_authors.rename(columns={\"paper_id\":\"paper_count\"}, inplace=True)\n",
    "top_authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_authors_list = [330, 1472, 178, 121, 1020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>title_len</th>\n",
       "      <th>paper_len</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>Oral</th>\n",
       "      <th>Poster</th>\n",
       "      <th>Spotlight</th>\n",
       "      <th>Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20270</th>\n",
       "      <td>1993</td>\n",
       "      <td>Supervised learning from incomplete\\ndata via ...</td>\n",
       "      <td>767</td>\n",
       "      <td>330</td>\n",
       "      <td>59</td>\n",
       "      <td>20948</td>\n",
       "      <td>5.151910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20269</th>\n",
       "      <td>1993</td>\n",
       "      <td>Supervised learning from incomplete\\ndata via ...</td>\n",
       "      <td>767</td>\n",
       "      <td>1020</td>\n",
       "      <td>59</td>\n",
       "      <td>20948</td>\n",
       "      <td>5.151910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20610</th>\n",
       "      <td>1994</td>\n",
       "      <td>An Alternative Model for Mixtures of\\nExperts\\...</td>\n",
       "      <td>906</td>\n",
       "      <td>121</td>\n",
       "      <td>44</td>\n",
       "      <td>17802</td>\n",
       "      <td>4.856669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20609</th>\n",
       "      <td>1994</td>\n",
       "      <td>An Alternative Model for Mixtures of\\nExperts\\...</td>\n",
       "      <td>906</td>\n",
       "      <td>330</td>\n",
       "      <td>44</td>\n",
       "      <td>17802</td>\n",
       "      <td>4.856669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20618</th>\n",
       "      <td>1994</td>\n",
       "      <td>Forward dynamic models in human\\nmotor control...</td>\n",
       "      <td>909</td>\n",
       "      <td>330</td>\n",
       "      <td>70</td>\n",
       "      <td>19430</td>\n",
       "      <td>5.095964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20617</th>\n",
       "      <td>1994</td>\n",
       "      <td>Forward dynamic models in human\\nmotor control...</td>\n",
       "      <td>909</td>\n",
       "      <td>1020</td>\n",
       "      <td>70</td>\n",
       "      <td>19430</td>\n",
       "      <td>5.095964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20705</th>\n",
       "      <td>1994</td>\n",
       "      <td>Computational structure of coordinate\\ntransfo...</td>\n",
       "      <td>948</td>\n",
       "      <td>330</td>\n",
       "      <td>77</td>\n",
       "      <td>21404</td>\n",
       "      <td>5.326837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20703</th>\n",
       "      <td>1994</td>\n",
       "      <td>Computational structure of coordinate\\ntransfo...</td>\n",
       "      <td>948</td>\n",
       "      <td>1020</td>\n",
       "      <td>77</td>\n",
       "      <td>21404</td>\n",
       "      <td>5.326837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1994</td>\n",
       "      <td>Active Learning with Statistical Models\\n\\nDav...</td>\n",
       "      <td>1011</td>\n",
       "      <td>1020</td>\n",
       "      <td>39</td>\n",
       "      <td>15512</td>\n",
       "      <td>5.052153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1994</td>\n",
       "      <td>Active Learning with Statistical Models\\n\\nDav...</td>\n",
       "      <td>1011</td>\n",
       "      <td>330</td>\n",
       "      <td>39</td>\n",
       "      <td>15512</td>\n",
       "      <td>5.052153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1995</td>\n",
       "      <td>Factorial Hidden Markov Models\\nZoubin Ghahram...</td>\n",
       "      <td>1144</td>\n",
       "      <td>330</td>\n",
       "      <td>30</td>\n",
       "      <td>19305</td>\n",
       "      <td>5.185567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1995</td>\n",
       "      <td>Factorial Hidden Markov Models\\nZoubin Ghahram...</td>\n",
       "      <td>1144</td>\n",
       "      <td>1020</td>\n",
       "      <td>30</td>\n",
       "      <td>19305</td>\n",
       "      <td>5.185567</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>1996</td>\n",
       "      <td>Hidden Markov decision trees\\nMichael I. Jorda...</td>\n",
       "      <td>1264</td>\n",
       "      <td>1020</td>\n",
       "      <td>28</td>\n",
       "      <td>18429</td>\n",
       "      <td>5.255123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>1996</td>\n",
       "      <td>Hidden Markov decision trees\\nMichael I. Jorda...</td>\n",
       "      <td>1264</td>\n",
       "      <td>330</td>\n",
       "      <td>28</td>\n",
       "      <td>18429</td>\n",
       "      <td>5.255123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>1997</td>\n",
       "      <td>Hierarchical Non-linear Factor Analysis\\nand T...</td>\n",
       "      <td>1472</td>\n",
       "      <td>121</td>\n",
       "      <td>60</td>\n",
       "      <td>21648</td>\n",
       "      <td>5.091629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>1997</td>\n",
       "      <td>Hierarchical Non-linear Factor Analysis\\nand T...</td>\n",
       "      <td>1472</td>\n",
       "      <td>1020</td>\n",
       "      <td>60</td>\n",
       "      <td>21648</td>\n",
       "      <td>5.091629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>1998</td>\n",
       "      <td>SMEM Algorithm for Mixture Models\\n\\nN aonori ...</td>\n",
       "      <td>1521</td>\n",
       "      <td>121</td>\n",
       "      <td>33</td>\n",
       "      <td>18686</td>\n",
       "      <td>4.903834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1998</td>\n",
       "      <td>SMEM Algorithm for Mixture Models\\n\\nN aonori ...</td>\n",
       "      <td>1521</td>\n",
       "      <td>1020</td>\n",
       "      <td>33</td>\n",
       "      <td>18686</td>\n",
       "      <td>4.903834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>1999</td>\n",
       "      <td>Learning to Parse Images\\n\\nGeoffrey E. Hinton...</td>\n",
       "      <td>1710</td>\n",
       "      <td>121</td>\n",
       "      <td>24</td>\n",
       "      <td>19240</td>\n",
       "      <td>5.012264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>1999</td>\n",
       "      <td>Learning to Parse Images\\n\\nGeoffrey E. Hinton...</td>\n",
       "      <td>1710</td>\n",
       "      <td>1020</td>\n",
       "      <td>24</td>\n",
       "      <td>19240</td>\n",
       "      <td>5.012264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9013</th>\n",
       "      <td>2010</td>\n",
       "      <td>Tree-Structured Stick Breaking for Hierarchica...</td>\n",
       "      <td>4108</td>\n",
       "      <td>1020</td>\n",
       "      <td>52</td>\n",
       "      <td>35332</td>\n",
       "      <td>4.931511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9014</th>\n",
       "      <td>2010</td>\n",
       "      <td>Tree-Structured Stick Breaking for Hierarchica...</td>\n",
       "      <td>4108</td>\n",
       "      <td>330</td>\n",
       "      <td>52</td>\n",
       "      <td>35332</td>\n",
       "      <td>4.931511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18911</th>\n",
       "      <td>2017</td>\n",
       "      <td>Interpolated Policy Gradient: Merging On-Polic...</td>\n",
       "      <td>6974</td>\n",
       "      <td>1020</td>\n",
       "      <td>114</td>\n",
       "      <td>37391</td>\n",
       "      <td>5.038567</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18912</th>\n",
       "      <td>2017</td>\n",
       "      <td>Interpolated Policy Gradient: Merging On-Polic...</td>\n",
       "      <td>6974</td>\n",
       "      <td>1472</td>\n",
       "      <td>114</td>\n",
       "      <td>37391</td>\n",
       "      <td>5.038567</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year                                         paper_text  paper_id  \\\n",
       "20270  1993  Supervised learning from incomplete\\ndata via ...       767   \n",
       "20269  1993  Supervised learning from incomplete\\ndata via ...       767   \n",
       "20610  1994  An Alternative Model for Mixtures of\\nExperts\\...       906   \n",
       "20609  1994  An Alternative Model for Mixtures of\\nExperts\\...       906   \n",
       "20618  1994  Forward dynamic models in human\\nmotor control...       909   \n",
       "20617  1994  Forward dynamic models in human\\nmotor control...       909   \n",
       "20705  1994  Computational structure of coordinate\\ntransfo...       948   \n",
       "20703  1994  Computational structure of coordinate\\ntransfo...       948   \n",
       "40     1994  Active Learning with Statistical Models\\n\\nDav...      1011   \n",
       "41     1994  Active Learning with Statistical Models\\n\\nDav...      1011   \n",
       "370    1995  Factorial Hidden Markov Models\\nZoubin Ghahram...      1144   \n",
       "369    1995  Factorial Hidden Markov Models\\nZoubin Ghahram...      1144   \n",
       "666    1996  Hidden Markov decision trees\\nMichael I. Jorda...      1264   \n",
       "665    1996  Hidden Markov decision trees\\nMichael I. Jorda...      1264   \n",
       "1171   1997  Hierarchical Non-linear Factor Analysis\\nand T...      1472   \n",
       "1170   1997  Hierarchical Non-linear Factor Analysis\\nand T...      1472   \n",
       "1301   1998  SMEM Algorithm for Mixture Models\\n\\nN aonori ...      1521   \n",
       "1300   1998  SMEM Algorithm for Mixture Models\\n\\nN aonori ...      1521   \n",
       "1787   1999  Learning to Parse Images\\n\\nGeoffrey E. Hinton...      1710   \n",
       "1788   1999  Learning to Parse Images\\n\\nGeoffrey E. Hinton...      1710   \n",
       "9013   2010  Tree-Structured Stick Breaking for Hierarchica...      4108   \n",
       "9014   2010  Tree-Structured Stick Breaking for Hierarchica...      4108   \n",
       "18911  2017  Interpolated Policy Gradient: Merging On-Polic...      6974   \n",
       "18912  2017  Interpolated Policy Gradient: Merging On-Polic...      6974   \n",
       "\n",
       "       author_id  title_len  paper_len  avg_word_len  Oral  Poster  Spotlight  \\\n",
       "20270        330         59      20948      5.151910     0       0          0   \n",
       "20269       1020         59      20948      5.151910     0       0          0   \n",
       "20610        121         44      17802      4.856669     0       0          0   \n",
       "20609        330         44      17802      4.856669     0       0          0   \n",
       "20618        330         70      19430      5.095964     0       0          0   \n",
       "20617       1020         70      19430      5.095964     0       0          0   \n",
       "20705        330         77      21404      5.326837     0       0          0   \n",
       "20703       1020         77      21404      5.326837     0       0          0   \n",
       "40          1020         39      15512      5.052153     0       0          0   \n",
       "41           330         39      15512      5.052153     0       0          0   \n",
       "370          330         30      19305      5.185567     0       0          0   \n",
       "369         1020         30      19305      5.185567     0       0          0   \n",
       "666         1020         28      18429      5.255123     0       0          0   \n",
       "665          330         28      18429      5.255123     0       0          0   \n",
       "1171         121         60      21648      5.091629     0       0          0   \n",
       "1170        1020         60      21648      5.091629     0       0          0   \n",
       "1301         121         33      18686      4.903834     0       0          0   \n",
       "1300        1020         33      18686      4.903834     0       0          0   \n",
       "1787         121         24      19240      5.012264     0       0          0   \n",
       "1788        1020         24      19240      5.012264     0       0          0   \n",
       "9013        1020         52      35332      4.931511     0       0          0   \n",
       "9014         330         52      35332      4.931511     0       0          0   \n",
       "18911       1020        114      37391      5.038567     0       1          0   \n",
       "18912       1472        114      37391      5.038567     0       1          0   \n",
       "\n",
       "       Unknown  \n",
       "20270        1  \n",
       "20269        1  \n",
       "20610        1  \n",
       "20609        1  \n",
       "20618        1  \n",
       "20617        1  \n",
       "20705        1  \n",
       "20703        1  \n",
       "40           1  \n",
       "41           1  \n",
       "370          1  \n",
       "369          1  \n",
       "666          1  \n",
       "665          1  \n",
       "1171         1  \n",
       "1170         1  \n",
       "1301         1  \n",
       "1300         1  \n",
       "1787         1  \n",
       "1788         1  \n",
       "9013         1  \n",
       "9014         1  \n",
       "18911        0  \n",
       "18912        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_papers = papers_and_authors[papers_and_authors['author_id'].isin(top_authors_list)]\n",
    "top_papers_duplicates = top_papers[top_papers.duplicated(subset='paper_id', keep=False)]\n",
    "top_papers_duplicates.sort_values(by='paper_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title_len</th>\n",
       "      <th>paper_len</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>Oral</th>\n",
       "      <th>Poster</th>\n",
       "      <th>Spotlight</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>...</th>\n",
       "      <th>author_id_10473</th>\n",
       "      <th>author_id_10474</th>\n",
       "      <th>author_id_10475</th>\n",
       "      <th>author_id_10476</th>\n",
       "      <th>author_id_10477</th>\n",
       "      <th>author_id_10478</th>\n",
       "      <th>author_id_10479</th>\n",
       "      <th>author_id_10480</th>\n",
       "      <th>author_id_10481</th>\n",
       "      <th>author_id_10482</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>21643</td>\n",
       "      <td>4.808264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>21643</td>\n",
       "      <td>4.808264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "      <td>15505</td>\n",
       "      <td>4.886807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "      <td>100</td>\n",
       "      <td>116</td>\n",
       "      <td>20523</td>\n",
       "      <td>5.784861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "      <td>100</td>\n",
       "      <td>116</td>\n",
       "      <td>20523</td>\n",
       "      <td>5.784861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9792 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                         paper_text  paper_id  \\\n",
       "0  1987  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...         1   \n",
       "1  1987  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...         1   \n",
       "2  1987  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...        10   \n",
       "3  1988  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...       100   \n",
       "4  1988  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...       100   \n",
       "\n",
       "   title_len  paper_len  avg_word_len  Oral  Poster  Spotlight  Unknown  ...  \\\n",
       "0         62      21643      4.808264     0       0          0        1  ...   \n",
       "1         62      21643      4.808264     0       0          0        1  ...   \n",
       "2         98      15505      4.886807     0       0          0        1  ...   \n",
       "3        116      20523      5.784861     0       0          0        1  ...   \n",
       "4        116      20523      5.784861     0       0          0        1  ...   \n",
       "\n",
       "   author_id_10473  author_id_10474  author_id_10475  author_id_10476  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   author_id_10477  author_id_10478  author_id_10479  author_id_10480  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   author_id_10481  author_id_10482  \n",
       "0                0                0  \n",
       "1                0                0  \n",
       "2                0                0  \n",
       "3                0                0  \n",
       "4                0                0  \n",
       "\n",
       "[5 rows x 9792 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(papers_and_authors, columns=['author_id'])\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 'first',\n",
       " 'paper_text': 'first',\n",
       " 'paper_id': 'first',\n",
       " 'title_len': 'first',\n",
       " 'paper_len': 'first',\n",
       " 'avg_word_len': 'first',\n",
       " 'Oral': 'first',\n",
       " 'Poster': 'first',\n",
       " 'Spotlight': 'first',\n",
       " 'Unknown': 'first',\n",
       " 'author_id_1': 'sum',\n",
       " 'author_id_2': 'sum',\n",
       " 'author_id_3': 'sum',\n",
       " 'author_id_4': 'sum',\n",
       " 'author_id_5': 'sum',\n",
       " 'author_id_6': 'sum',\n",
       " 'author_id_7': 'sum',\n",
       " 'author_id_8': 'sum',\n",
       " 'author_id_9': 'sum',\n",
       " 'author_id_10': 'sum',\n",
       " 'author_id_11': 'sum',\n",
       " 'author_id_12': 'sum',\n",
       " 'author_id_13': 'sum',\n",
       " 'author_id_14': 'sum',\n",
       " 'author_id_15': 'sum',\n",
       " 'author_id_16': 'sum',\n",
       " 'author_id_17': 'sum',\n",
       " 'author_id_18': 'sum',\n",
       " 'author_id_19': 'sum',\n",
       " 'author_id_20': 'sum',\n",
       " 'author_id_21': 'sum',\n",
       " 'author_id_22': 'sum',\n",
       " 'author_id_23': 'sum',\n",
       " 'author_id_24': 'sum',\n",
       " 'author_id_25': 'sum',\n",
       " 'author_id_26': 'sum',\n",
       " 'author_id_27': 'sum',\n",
       " 'author_id_28': 'sum',\n",
       " 'author_id_29': 'sum',\n",
       " 'author_id_30': 'sum',\n",
       " 'author_id_31': 'sum',\n",
       " 'author_id_32': 'sum',\n",
       " 'author_id_33': 'sum',\n",
       " 'author_id_34': 'sum',\n",
       " 'author_id_35': 'sum',\n",
       " 'author_id_36': 'sum',\n",
       " 'author_id_37': 'sum',\n",
       " 'author_id_38': 'sum',\n",
       " 'author_id_39': 'sum',\n",
       " 'author_id_40': 'sum',\n",
       " 'author_id_41': 'sum',\n",
       " 'author_id_42': 'sum',\n",
       " 'author_id_43': 'sum',\n",
       " 'author_id_44': 'sum',\n",
       " 'author_id_45': 'sum',\n",
       " 'author_id_46': 'sum',\n",
       " 'author_id_47': 'sum',\n",
       " 'author_id_48': 'sum',\n",
       " 'author_id_49': 'sum',\n",
       " 'author_id_50': 'sum',\n",
       " 'author_id_51': 'sum',\n",
       " 'author_id_52': 'sum',\n",
       " 'author_id_53': 'sum',\n",
       " 'author_id_54': 'sum',\n",
       " 'author_id_55': 'sum',\n",
       " 'author_id_56': 'sum',\n",
       " 'author_id_57': 'sum',\n",
       " 'author_id_58': 'sum',\n",
       " 'author_id_59': 'sum',\n",
       " 'author_id_60': 'sum',\n",
       " 'author_id_61': 'sum',\n",
       " 'author_id_62': 'sum',\n",
       " 'author_id_63': 'sum',\n",
       " 'author_id_64': 'sum',\n",
       " 'author_id_65': 'sum',\n",
       " 'author_id_66': 'sum',\n",
       " 'author_id_67': 'sum',\n",
       " 'author_id_68': 'sum',\n",
       " 'author_id_69': 'sum',\n",
       " 'author_id_70': 'sum',\n",
       " 'author_id_71': 'sum',\n",
       " 'author_id_72': 'sum',\n",
       " 'author_id_74': 'sum',\n",
       " 'author_id_75': 'sum',\n",
       " 'author_id_76': 'sum',\n",
       " 'author_id_77': 'sum',\n",
       " 'author_id_78': 'sum',\n",
       " 'author_id_79': 'sum',\n",
       " 'author_id_80': 'sum',\n",
       " 'author_id_81': 'sum',\n",
       " 'author_id_82': 'sum',\n",
       " 'author_id_83': 'sum',\n",
       " 'author_id_84': 'sum',\n",
       " 'author_id_85': 'sum',\n",
       " 'author_id_86': 'sum',\n",
       " 'author_id_87': 'sum',\n",
       " 'author_id_88': 'sum',\n",
       " 'author_id_89': 'sum',\n",
       " 'author_id_90': 'sum',\n",
       " 'author_id_91': 'sum',\n",
       " 'author_id_92': 'sum',\n",
       " 'author_id_93': 'sum',\n",
       " 'author_id_94': 'sum',\n",
       " 'author_id_95': 'sum',\n",
       " 'author_id_96': 'sum',\n",
       " 'author_id_97': 'sum',\n",
       " 'author_id_98': 'sum',\n",
       " 'author_id_99': 'sum',\n",
       " 'author_id_100': 'sum',\n",
       " 'author_id_101': 'sum',\n",
       " 'author_id_102': 'sum',\n",
       " 'author_id_103': 'sum',\n",
       " 'author_id_104': 'sum',\n",
       " 'author_id_105': 'sum',\n",
       " 'author_id_106': 'sum',\n",
       " 'author_id_107': 'sum',\n",
       " 'author_id_108': 'sum',\n",
       " 'author_id_109': 'sum',\n",
       " 'author_id_110': 'sum',\n",
       " 'author_id_111': 'sum',\n",
       " 'author_id_112': 'sum',\n",
       " 'author_id_113': 'sum',\n",
       " 'author_id_114': 'sum',\n",
       " 'author_id_115': 'sum',\n",
       " 'author_id_116': 'sum',\n",
       " 'author_id_117': 'sum',\n",
       " 'author_id_118': 'sum',\n",
       " 'author_id_119': 'sum',\n",
       " 'author_id_120': 'sum',\n",
       " 'author_id_121': 'sum',\n",
       " 'author_id_122': 'sum',\n",
       " 'author_id_123': 'sum',\n",
       " 'author_id_124': 'sum',\n",
       " 'author_id_125': 'sum',\n",
       " 'author_id_126': 'sum',\n",
       " 'author_id_127': 'sum',\n",
       " 'author_id_128': 'sum',\n",
       " 'author_id_129': 'sum',\n",
       " 'author_id_130': 'sum',\n",
       " 'author_id_131': 'sum',\n",
       " 'author_id_132': 'sum',\n",
       " 'author_id_133': 'sum',\n",
       " 'author_id_134': 'sum',\n",
       " 'author_id_135': 'sum',\n",
       " 'author_id_136': 'sum',\n",
       " 'author_id_137': 'sum',\n",
       " 'author_id_138': 'sum',\n",
       " 'author_id_139': 'sum',\n",
       " 'author_id_140': 'sum',\n",
       " 'author_id_141': 'sum',\n",
       " 'author_id_142': 'sum',\n",
       " 'author_id_143': 'sum',\n",
       " 'author_id_144': 'sum',\n",
       " 'author_id_145': 'sum',\n",
       " 'author_id_146': 'sum',\n",
       " 'author_id_147': 'sum',\n",
       " 'author_id_148': 'sum',\n",
       " 'author_id_149': 'sum',\n",
       " 'author_id_150': 'sum',\n",
       " 'author_id_152': 'sum',\n",
       " 'author_id_153': 'sum',\n",
       " 'author_id_154': 'sum',\n",
       " 'author_id_155': 'sum',\n",
       " 'author_id_156': 'sum',\n",
       " 'author_id_157': 'sum',\n",
       " 'author_id_158': 'sum',\n",
       " 'author_id_159': 'sum',\n",
       " 'author_id_160': 'sum',\n",
       " 'author_id_161': 'sum',\n",
       " 'author_id_162': 'sum',\n",
       " 'author_id_163': 'sum',\n",
       " 'author_id_164': 'sum',\n",
       " 'author_id_165': 'sum',\n",
       " 'author_id_166': 'sum',\n",
       " 'author_id_167': 'sum',\n",
       " 'author_id_168': 'sum',\n",
       " 'author_id_169': 'sum',\n",
       " 'author_id_170': 'sum',\n",
       " 'author_id_171': 'sum',\n",
       " 'author_id_172': 'sum',\n",
       " 'author_id_173': 'sum',\n",
       " 'author_id_174': 'sum',\n",
       " 'author_id_175': 'sum',\n",
       " 'author_id_176': 'sum',\n",
       " 'author_id_177': 'sum',\n",
       " 'author_id_178': 'sum',\n",
       " 'author_id_179': 'sum',\n",
       " 'author_id_180': 'sum',\n",
       " 'author_id_181': 'sum',\n",
       " 'author_id_182': 'sum',\n",
       " 'author_id_183': 'sum',\n",
       " 'author_id_184': 'sum',\n",
       " 'author_id_186': 'sum',\n",
       " 'author_id_188': 'sum',\n",
       " 'author_id_189': 'sum',\n",
       " 'author_id_190': 'sum',\n",
       " 'author_id_191': 'sum',\n",
       " 'author_id_192': 'sum',\n",
       " 'author_id_195': 'sum',\n",
       " 'author_id_196': 'sum',\n",
       " 'author_id_197': 'sum',\n",
       " 'author_id_198': 'sum',\n",
       " 'author_id_199': 'sum',\n",
       " 'author_id_200': 'sum',\n",
       " 'author_id_201': 'sum',\n",
       " 'author_id_202': 'sum',\n",
       " 'author_id_203': 'sum',\n",
       " 'author_id_204': 'sum',\n",
       " 'author_id_205': 'sum',\n",
       " 'author_id_206': 'sum',\n",
       " 'author_id_207': 'sum',\n",
       " 'author_id_208': 'sum',\n",
       " 'author_id_209': 'sum',\n",
       " 'author_id_210': 'sum',\n",
       " 'author_id_211': 'sum',\n",
       " 'author_id_212': 'sum',\n",
       " 'author_id_213': 'sum',\n",
       " 'author_id_214': 'sum',\n",
       " 'author_id_216': 'sum',\n",
       " 'author_id_217': 'sum',\n",
       " 'author_id_218': 'sum',\n",
       " 'author_id_219': 'sum',\n",
       " 'author_id_220': 'sum',\n",
       " 'author_id_221': 'sum',\n",
       " 'author_id_222': 'sum',\n",
       " 'author_id_224': 'sum',\n",
       " 'author_id_225': 'sum',\n",
       " 'author_id_226': 'sum',\n",
       " 'author_id_227': 'sum',\n",
       " 'author_id_228': 'sum',\n",
       " 'author_id_229': 'sum',\n",
       " 'author_id_230': 'sum',\n",
       " 'author_id_231': 'sum',\n",
       " 'author_id_232': 'sum',\n",
       " 'author_id_233': 'sum',\n",
       " 'author_id_234': 'sum',\n",
       " 'author_id_235': 'sum',\n",
       " 'author_id_236': 'sum',\n",
       " 'author_id_237': 'sum',\n",
       " 'author_id_238': 'sum',\n",
       " 'author_id_239': 'sum',\n",
       " 'author_id_240': 'sum',\n",
       " 'author_id_241': 'sum',\n",
       " 'author_id_242': 'sum',\n",
       " 'author_id_243': 'sum',\n",
       " 'author_id_244': 'sum',\n",
       " 'author_id_245': 'sum',\n",
       " 'author_id_246': 'sum',\n",
       " 'author_id_247': 'sum',\n",
       " 'author_id_248': 'sum',\n",
       " 'author_id_249': 'sum',\n",
       " 'author_id_250': 'sum',\n",
       " 'author_id_251': 'sum',\n",
       " 'author_id_252': 'sum',\n",
       " 'author_id_253': 'sum',\n",
       " 'author_id_254': 'sum',\n",
       " 'author_id_255': 'sum',\n",
       " 'author_id_256': 'sum',\n",
       " 'author_id_257': 'sum',\n",
       " 'author_id_258': 'sum',\n",
       " 'author_id_259': 'sum',\n",
       " 'author_id_260': 'sum',\n",
       " 'author_id_261': 'sum',\n",
       " 'author_id_262': 'sum',\n",
       " 'author_id_263': 'sum',\n",
       " 'author_id_264': 'sum',\n",
       " 'author_id_265': 'sum',\n",
       " 'author_id_267': 'sum',\n",
       " 'author_id_268': 'sum',\n",
       " 'author_id_269': 'sum',\n",
       " 'author_id_270': 'sum',\n",
       " 'author_id_271': 'sum',\n",
       " 'author_id_272': 'sum',\n",
       " 'author_id_273': 'sum',\n",
       " 'author_id_274': 'sum',\n",
       " 'author_id_275': 'sum',\n",
       " 'author_id_276': 'sum',\n",
       " 'author_id_277': 'sum',\n",
       " 'author_id_278': 'sum',\n",
       " 'author_id_279': 'sum',\n",
       " 'author_id_280': 'sum',\n",
       " 'author_id_281': 'sum',\n",
       " 'author_id_282': 'sum',\n",
       " 'author_id_283': 'sum',\n",
       " 'author_id_284': 'sum',\n",
       " 'author_id_285': 'sum',\n",
       " 'author_id_286': 'sum',\n",
       " 'author_id_287': 'sum',\n",
       " 'author_id_288': 'sum',\n",
       " 'author_id_289': 'sum',\n",
       " 'author_id_290': 'sum',\n",
       " 'author_id_291': 'sum',\n",
       " 'author_id_292': 'sum',\n",
       " 'author_id_293': 'sum',\n",
       " 'author_id_294': 'sum',\n",
       " 'author_id_295': 'sum',\n",
       " 'author_id_296': 'sum',\n",
       " 'author_id_297': 'sum',\n",
       " 'author_id_298': 'sum',\n",
       " 'author_id_299': 'sum',\n",
       " 'author_id_300': 'sum',\n",
       " 'author_id_301': 'sum',\n",
       " 'author_id_302': 'sum',\n",
       " 'author_id_303': 'sum',\n",
       " 'author_id_304': 'sum',\n",
       " 'author_id_305': 'sum',\n",
       " 'author_id_306': 'sum',\n",
       " 'author_id_307': 'sum',\n",
       " 'author_id_308': 'sum',\n",
       " 'author_id_309': 'sum',\n",
       " 'author_id_310': 'sum',\n",
       " 'author_id_313': 'sum',\n",
       " 'author_id_314': 'sum',\n",
       " 'author_id_315': 'sum',\n",
       " 'author_id_316': 'sum',\n",
       " 'author_id_317': 'sum',\n",
       " 'author_id_318': 'sum',\n",
       " 'author_id_319': 'sum',\n",
       " 'author_id_320': 'sum',\n",
       " 'author_id_321': 'sum',\n",
       " 'author_id_322': 'sum',\n",
       " 'author_id_323': 'sum',\n",
       " 'author_id_324': 'sum',\n",
       " 'author_id_325': 'sum',\n",
       " 'author_id_326': 'sum',\n",
       " 'author_id_327': 'sum',\n",
       " 'author_id_328': 'sum',\n",
       " 'author_id_329': 'sum',\n",
       " 'author_id_330': 'sum',\n",
       " 'author_id_331': 'sum',\n",
       " 'author_id_332': 'sum',\n",
       " 'author_id_333': 'sum',\n",
       " 'author_id_334': 'sum',\n",
       " 'author_id_335': 'sum',\n",
       " 'author_id_336': 'sum',\n",
       " 'author_id_337': 'sum',\n",
       " 'author_id_338': 'sum',\n",
       " 'author_id_339': 'sum',\n",
       " 'author_id_340': 'sum',\n",
       " 'author_id_341': 'sum',\n",
       " 'author_id_342': 'sum',\n",
       " 'author_id_343': 'sum',\n",
       " 'author_id_344': 'sum',\n",
       " 'author_id_345': 'sum',\n",
       " 'author_id_346': 'sum',\n",
       " 'author_id_347': 'sum',\n",
       " 'author_id_348': 'sum',\n",
       " 'author_id_349': 'sum',\n",
       " 'author_id_350': 'sum',\n",
       " 'author_id_351': 'sum',\n",
       " 'author_id_352': 'sum',\n",
       " 'author_id_353': 'sum',\n",
       " 'author_id_354': 'sum',\n",
       " 'author_id_355': 'sum',\n",
       " 'author_id_356': 'sum',\n",
       " 'author_id_357': 'sum',\n",
       " 'author_id_358': 'sum',\n",
       " 'author_id_359': 'sum',\n",
       " 'author_id_360': 'sum',\n",
       " 'author_id_361': 'sum',\n",
       " 'author_id_362': 'sum',\n",
       " 'author_id_363': 'sum',\n",
       " 'author_id_364': 'sum',\n",
       " 'author_id_365': 'sum',\n",
       " 'author_id_366': 'sum',\n",
       " 'author_id_367': 'sum',\n",
       " 'author_id_368': 'sum',\n",
       " 'author_id_369': 'sum',\n",
       " 'author_id_370': 'sum',\n",
       " 'author_id_371': 'sum',\n",
       " 'author_id_372': 'sum',\n",
       " 'author_id_373': 'sum',\n",
       " 'author_id_374': 'sum',\n",
       " 'author_id_375': 'sum',\n",
       " 'author_id_376': 'sum',\n",
       " 'author_id_377': 'sum',\n",
       " 'author_id_378': 'sum',\n",
       " 'author_id_379': 'sum',\n",
       " 'author_id_380': 'sum',\n",
       " 'author_id_381': 'sum',\n",
       " 'author_id_382': 'sum',\n",
       " 'author_id_383': 'sum',\n",
       " 'author_id_384': 'sum',\n",
       " 'author_id_385': 'sum',\n",
       " 'author_id_386': 'sum',\n",
       " 'author_id_387': 'sum',\n",
       " 'author_id_388': 'sum',\n",
       " 'author_id_389': 'sum',\n",
       " 'author_id_390': 'sum',\n",
       " 'author_id_391': 'sum',\n",
       " 'author_id_392': 'sum',\n",
       " 'author_id_393': 'sum',\n",
       " 'author_id_394': 'sum',\n",
       " 'author_id_395': 'sum',\n",
       " 'author_id_396': 'sum',\n",
       " 'author_id_397': 'sum',\n",
       " 'author_id_398': 'sum',\n",
       " 'author_id_399': 'sum',\n",
       " 'author_id_400': 'sum',\n",
       " 'author_id_401': 'sum',\n",
       " 'author_id_402': 'sum',\n",
       " 'author_id_403': 'sum',\n",
       " 'author_id_404': 'sum',\n",
       " 'author_id_405': 'sum',\n",
       " 'author_id_406': 'sum',\n",
       " 'author_id_407': 'sum',\n",
       " 'author_id_408': 'sum',\n",
       " 'author_id_409': 'sum',\n",
       " 'author_id_410': 'sum',\n",
       " 'author_id_411': 'sum',\n",
       " 'author_id_412': 'sum',\n",
       " 'author_id_413': 'sum',\n",
       " 'author_id_414': 'sum',\n",
       " 'author_id_415': 'sum',\n",
       " 'author_id_416': 'sum',\n",
       " 'author_id_417': 'sum',\n",
       " 'author_id_418': 'sum',\n",
       " 'author_id_419': 'sum',\n",
       " 'author_id_420': 'sum',\n",
       " 'author_id_421': 'sum',\n",
       " 'author_id_422': 'sum',\n",
       " 'author_id_423': 'sum',\n",
       " 'author_id_424': 'sum',\n",
       " 'author_id_425': 'sum',\n",
       " 'author_id_426': 'sum',\n",
       " 'author_id_427': 'sum',\n",
       " 'author_id_428': 'sum',\n",
       " 'author_id_429': 'sum',\n",
       " 'author_id_430': 'sum',\n",
       " 'author_id_431': 'sum',\n",
       " 'author_id_432': 'sum',\n",
       " 'author_id_433': 'sum',\n",
       " 'author_id_434': 'sum',\n",
       " 'author_id_435': 'sum',\n",
       " 'author_id_436': 'sum',\n",
       " 'author_id_437': 'sum',\n",
       " 'author_id_438': 'sum',\n",
       " 'author_id_439': 'sum',\n",
       " 'author_id_440': 'sum',\n",
       " 'author_id_441': 'sum',\n",
       " 'author_id_442': 'sum',\n",
       " 'author_id_443': 'sum',\n",
       " 'author_id_444': 'sum',\n",
       " 'author_id_445': 'sum',\n",
       " 'author_id_446': 'sum',\n",
       " 'author_id_447': 'sum',\n",
       " 'author_id_448': 'sum',\n",
       " 'author_id_449': 'sum',\n",
       " 'author_id_450': 'sum',\n",
       " 'author_id_451': 'sum',\n",
       " 'author_id_452': 'sum',\n",
       " 'author_id_453': 'sum',\n",
       " 'author_id_454': 'sum',\n",
       " 'author_id_455': 'sum',\n",
       " 'author_id_457': 'sum',\n",
       " 'author_id_458': 'sum',\n",
       " 'author_id_459': 'sum',\n",
       " 'author_id_460': 'sum',\n",
       " 'author_id_461': 'sum',\n",
       " 'author_id_462': 'sum',\n",
       " 'author_id_463': 'sum',\n",
       " 'author_id_464': 'sum',\n",
       " 'author_id_465': 'sum',\n",
       " 'author_id_466': 'sum',\n",
       " 'author_id_467': 'sum',\n",
       " 'author_id_468': 'sum',\n",
       " 'author_id_469': 'sum',\n",
       " 'author_id_471': 'sum',\n",
       " 'author_id_472': 'sum',\n",
       " 'author_id_473': 'sum',\n",
       " 'author_id_474': 'sum',\n",
       " 'author_id_475': 'sum',\n",
       " 'author_id_476': 'sum',\n",
       " 'author_id_477': 'sum',\n",
       " 'author_id_478': 'sum',\n",
       " 'author_id_479': 'sum',\n",
       " 'author_id_480': 'sum',\n",
       " 'author_id_481': 'sum',\n",
       " 'author_id_482': 'sum',\n",
       " 'author_id_483': 'sum',\n",
       " 'author_id_484': 'sum',\n",
       " 'author_id_485': 'sum',\n",
       " 'author_id_486': 'sum',\n",
       " 'author_id_487': 'sum',\n",
       " 'author_id_488': 'sum',\n",
       " 'author_id_489': 'sum',\n",
       " 'author_id_490': 'sum',\n",
       " 'author_id_491': 'sum',\n",
       " 'author_id_492': 'sum',\n",
       " 'author_id_493': 'sum',\n",
       " 'author_id_494': 'sum',\n",
       " 'author_id_496': 'sum',\n",
       " 'author_id_497': 'sum',\n",
       " 'author_id_498': 'sum',\n",
       " 'author_id_499': 'sum',\n",
       " 'author_id_500': 'sum',\n",
       " 'author_id_501': 'sum',\n",
       " 'author_id_502': 'sum',\n",
       " 'author_id_503': 'sum',\n",
       " 'author_id_504': 'sum',\n",
       " 'author_id_505': 'sum',\n",
       " 'author_id_506': 'sum',\n",
       " 'author_id_507': 'sum',\n",
       " 'author_id_508': 'sum',\n",
       " 'author_id_509': 'sum',\n",
       " 'author_id_510': 'sum',\n",
       " 'author_id_511': 'sum',\n",
       " 'author_id_512': 'sum',\n",
       " 'author_id_513': 'sum',\n",
       " 'author_id_514': 'sum',\n",
       " 'author_id_516': 'sum',\n",
       " 'author_id_517': 'sum',\n",
       " 'author_id_518': 'sum',\n",
       " 'author_id_519': 'sum',\n",
       " 'author_id_520': 'sum',\n",
       " 'author_id_521': 'sum',\n",
       " 'author_id_522': 'sum',\n",
       " 'author_id_523': 'sum',\n",
       " 'author_id_524': 'sum',\n",
       " 'author_id_525': 'sum',\n",
       " 'author_id_526': 'sum',\n",
       " 'author_id_527': 'sum',\n",
       " 'author_id_528': 'sum',\n",
       " 'author_id_529': 'sum',\n",
       " 'author_id_530': 'sum',\n",
       " 'author_id_531': 'sum',\n",
       " 'author_id_532': 'sum',\n",
       " 'author_id_533': 'sum',\n",
       " 'author_id_534': 'sum',\n",
       " 'author_id_535': 'sum',\n",
       " 'author_id_537': 'sum',\n",
       " 'author_id_539': 'sum',\n",
       " 'author_id_540': 'sum',\n",
       " 'author_id_541': 'sum',\n",
       " 'author_id_542': 'sum',\n",
       " 'author_id_543': 'sum',\n",
       " 'author_id_544': 'sum',\n",
       " 'author_id_545': 'sum',\n",
       " 'author_id_546': 'sum',\n",
       " 'author_id_547': 'sum',\n",
       " 'author_id_548': 'sum',\n",
       " 'author_id_549': 'sum',\n",
       " 'author_id_550': 'sum',\n",
       " 'author_id_551': 'sum',\n",
       " 'author_id_552': 'sum',\n",
       " 'author_id_554': 'sum',\n",
       " 'author_id_555': 'sum',\n",
       " 'author_id_556': 'sum',\n",
       " 'author_id_557': 'sum',\n",
       " 'author_id_558': 'sum',\n",
       " 'author_id_559': 'sum',\n",
       " 'author_id_560': 'sum',\n",
       " 'author_id_561': 'sum',\n",
       " 'author_id_562': 'sum',\n",
       " 'author_id_563': 'sum',\n",
       " 'author_id_564': 'sum',\n",
       " 'author_id_565': 'sum',\n",
       " 'author_id_566': 'sum',\n",
       " 'author_id_567': 'sum',\n",
       " 'author_id_568': 'sum',\n",
       " 'author_id_569': 'sum',\n",
       " 'author_id_570': 'sum',\n",
       " 'author_id_571': 'sum',\n",
       " 'author_id_572': 'sum',\n",
       " 'author_id_573': 'sum',\n",
       " 'author_id_574': 'sum',\n",
       " 'author_id_575': 'sum',\n",
       " 'author_id_576': 'sum',\n",
       " 'author_id_577': 'sum',\n",
       " 'author_id_578': 'sum',\n",
       " 'author_id_579': 'sum',\n",
       " 'author_id_580': 'sum',\n",
       " 'author_id_581': 'sum',\n",
       " 'author_id_582': 'sum',\n",
       " 'author_id_583': 'sum',\n",
       " 'author_id_584': 'sum',\n",
       " 'author_id_585': 'sum',\n",
       " 'author_id_586': 'sum',\n",
       " 'author_id_587': 'sum',\n",
       " 'author_id_588': 'sum',\n",
       " 'author_id_589': 'sum',\n",
       " 'author_id_590': 'sum',\n",
       " 'author_id_591': 'sum',\n",
       " 'author_id_592': 'sum',\n",
       " 'author_id_593': 'sum',\n",
       " 'author_id_594': 'sum',\n",
       " 'author_id_595': 'sum',\n",
       " 'author_id_596': 'sum',\n",
       " 'author_id_597': 'sum',\n",
       " 'author_id_598': 'sum',\n",
       " 'author_id_599': 'sum',\n",
       " 'author_id_601': 'sum',\n",
       " 'author_id_602': 'sum',\n",
       " 'author_id_603': 'sum',\n",
       " 'author_id_604': 'sum',\n",
       " 'author_id_605': 'sum',\n",
       " 'author_id_606': 'sum',\n",
       " 'author_id_607': 'sum',\n",
       " 'author_id_608': 'sum',\n",
       " 'author_id_609': 'sum',\n",
       " 'author_id_610': 'sum',\n",
       " 'author_id_611': 'sum',\n",
       " 'author_id_612': 'sum',\n",
       " 'author_id_614': 'sum',\n",
       " 'author_id_615': 'sum',\n",
       " 'author_id_616': 'sum',\n",
       " 'author_id_617': 'sum',\n",
       " 'author_id_618': 'sum',\n",
       " 'author_id_619': 'sum',\n",
       " 'author_id_620': 'sum',\n",
       " 'author_id_621': 'sum',\n",
       " 'author_id_622': 'sum',\n",
       " 'author_id_624': 'sum',\n",
       " 'author_id_625': 'sum',\n",
       " 'author_id_626': 'sum',\n",
       " 'author_id_627': 'sum',\n",
       " 'author_id_628': 'sum',\n",
       " 'author_id_629': 'sum',\n",
       " 'author_id_630': 'sum',\n",
       " 'author_id_631': 'sum',\n",
       " 'author_id_632': 'sum',\n",
       " 'author_id_633': 'sum',\n",
       " 'author_id_634': 'sum',\n",
       " 'author_id_635': 'sum',\n",
       " 'author_id_636': 'sum',\n",
       " 'author_id_637': 'sum',\n",
       " 'author_id_638': 'sum',\n",
       " 'author_id_639': 'sum',\n",
       " 'author_id_640': 'sum',\n",
       " 'author_id_641': 'sum',\n",
       " 'author_id_642': 'sum',\n",
       " 'author_id_643': 'sum',\n",
       " 'author_id_644': 'sum',\n",
       " 'author_id_645': 'sum',\n",
       " 'author_id_646': 'sum',\n",
       " 'author_id_647': 'sum',\n",
       " 'author_id_648': 'sum',\n",
       " 'author_id_649': 'sum',\n",
       " 'author_id_650': 'sum',\n",
       " 'author_id_651': 'sum',\n",
       " 'author_id_652': 'sum',\n",
       " 'author_id_653': 'sum',\n",
       " 'author_id_654': 'sum',\n",
       " 'author_id_655': 'sum',\n",
       " 'author_id_656': 'sum',\n",
       " 'author_id_657': 'sum',\n",
       " 'author_id_658': 'sum',\n",
       " 'author_id_659': 'sum',\n",
       " 'author_id_660': 'sum',\n",
       " 'author_id_661': 'sum',\n",
       " 'author_id_662': 'sum',\n",
       " 'author_id_663': 'sum',\n",
       " 'author_id_664': 'sum',\n",
       " 'author_id_666': 'sum',\n",
       " 'author_id_667': 'sum',\n",
       " 'author_id_668': 'sum',\n",
       " 'author_id_669': 'sum',\n",
       " 'author_id_670': 'sum',\n",
       " 'author_id_671': 'sum',\n",
       " 'author_id_672': 'sum',\n",
       " 'author_id_673': 'sum',\n",
       " 'author_id_674': 'sum',\n",
       " 'author_id_675': 'sum',\n",
       " 'author_id_676': 'sum',\n",
       " 'author_id_677': 'sum',\n",
       " 'author_id_678': 'sum',\n",
       " 'author_id_679': 'sum',\n",
       " 'author_id_680': 'sum',\n",
       " 'author_id_681': 'sum',\n",
       " 'author_id_682': 'sum',\n",
       " 'author_id_683': 'sum',\n",
       " 'author_id_684': 'sum',\n",
       " 'author_id_685': 'sum',\n",
       " 'author_id_686': 'sum',\n",
       " 'author_id_687': 'sum',\n",
       " 'author_id_688': 'sum',\n",
       " 'author_id_689': 'sum',\n",
       " 'author_id_690': 'sum',\n",
       " 'author_id_692': 'sum',\n",
       " 'author_id_693': 'sum',\n",
       " 'author_id_694': 'sum',\n",
       " 'author_id_695': 'sum',\n",
       " 'author_id_696': 'sum',\n",
       " 'author_id_697': 'sum',\n",
       " 'author_id_698': 'sum',\n",
       " 'author_id_699': 'sum',\n",
       " 'author_id_700': 'sum',\n",
       " 'author_id_701': 'sum',\n",
       " 'author_id_703': 'sum',\n",
       " 'author_id_704': 'sum',\n",
       " 'author_id_705': 'sum',\n",
       " 'author_id_706': 'sum',\n",
       " 'author_id_707': 'sum',\n",
       " 'author_id_708': 'sum',\n",
       " 'author_id_709': 'sum',\n",
       " 'author_id_710': 'sum',\n",
       " 'author_id_711': 'sum',\n",
       " 'author_id_714': 'sum',\n",
       " 'author_id_715': 'sum',\n",
       " 'author_id_716': 'sum',\n",
       " 'author_id_717': 'sum',\n",
       " 'author_id_719': 'sum',\n",
       " 'author_id_721': 'sum',\n",
       " 'author_id_722': 'sum',\n",
       " 'author_id_723': 'sum',\n",
       " 'author_id_724': 'sum',\n",
       " 'author_id_725': 'sum',\n",
       " 'author_id_726': 'sum',\n",
       " 'author_id_727': 'sum',\n",
       " 'author_id_728': 'sum',\n",
       " 'author_id_729': 'sum',\n",
       " 'author_id_730': 'sum',\n",
       " 'author_id_731': 'sum',\n",
       " 'author_id_732': 'sum',\n",
       " 'author_id_733': 'sum',\n",
       " 'author_id_734': 'sum',\n",
       " 'author_id_735': 'sum',\n",
       " 'author_id_736': 'sum',\n",
       " 'author_id_737': 'sum',\n",
       " 'author_id_738': 'sum',\n",
       " 'author_id_739': 'sum',\n",
       " 'author_id_740': 'sum',\n",
       " 'author_id_741': 'sum',\n",
       " 'author_id_742': 'sum',\n",
       " 'author_id_743': 'sum',\n",
       " 'author_id_744': 'sum',\n",
       " 'author_id_745': 'sum',\n",
       " 'author_id_746': 'sum',\n",
       " 'author_id_747': 'sum',\n",
       " 'author_id_748': 'sum',\n",
       " 'author_id_749': 'sum',\n",
       " 'author_id_750': 'sum',\n",
       " 'author_id_751': 'sum',\n",
       " 'author_id_752': 'sum',\n",
       " 'author_id_753': 'sum',\n",
       " 'author_id_754': 'sum',\n",
       " 'author_id_755': 'sum',\n",
       " 'author_id_756': 'sum',\n",
       " 'author_id_757': 'sum',\n",
       " 'author_id_758': 'sum',\n",
       " 'author_id_759': 'sum',\n",
       " 'author_id_760': 'sum',\n",
       " 'author_id_761': 'sum',\n",
       " 'author_id_762': 'sum',\n",
       " 'author_id_763': 'sum',\n",
       " 'author_id_764': 'sum',\n",
       " 'author_id_765': 'sum',\n",
       " 'author_id_766': 'sum',\n",
       " 'author_id_767': 'sum',\n",
       " 'author_id_768': 'sum',\n",
       " 'author_id_769': 'sum',\n",
       " 'author_id_770': 'sum',\n",
       " 'author_id_771': 'sum',\n",
       " 'author_id_772': 'sum',\n",
       " 'author_id_773': 'sum',\n",
       " 'author_id_774': 'sum',\n",
       " 'author_id_775': 'sum',\n",
       " 'author_id_776': 'sum',\n",
       " 'author_id_778': 'sum',\n",
       " 'author_id_779': 'sum',\n",
       " 'author_id_780': 'sum',\n",
       " 'author_id_781': 'sum',\n",
       " 'author_id_782': 'sum',\n",
       " 'author_id_783': 'sum',\n",
       " 'author_id_784': 'sum',\n",
       " 'author_id_785': 'sum',\n",
       " 'author_id_786': 'sum',\n",
       " 'author_id_787': 'sum',\n",
       " 'author_id_788': 'sum',\n",
       " 'author_id_789': 'sum',\n",
       " 'author_id_790': 'sum',\n",
       " 'author_id_791': 'sum',\n",
       " 'author_id_792': 'sum',\n",
       " 'author_id_793': 'sum',\n",
       " 'author_id_795': 'sum',\n",
       " 'author_id_796': 'sum',\n",
       " 'author_id_797': 'sum',\n",
       " 'author_id_798': 'sum',\n",
       " 'author_id_799': 'sum',\n",
       " 'author_id_800': 'sum',\n",
       " 'author_id_801': 'sum',\n",
       " 'author_id_802': 'sum',\n",
       " 'author_id_803': 'sum',\n",
       " 'author_id_804': 'sum',\n",
       " 'author_id_805': 'sum',\n",
       " 'author_id_806': 'sum',\n",
       " 'author_id_807': 'sum',\n",
       " 'author_id_808': 'sum',\n",
       " 'author_id_809': 'sum',\n",
       " 'author_id_810': 'sum',\n",
       " 'author_id_811': 'sum',\n",
       " 'author_id_812': 'sum',\n",
       " 'author_id_813': 'sum',\n",
       " 'author_id_814': 'sum',\n",
       " 'author_id_815': 'sum',\n",
       " 'author_id_816': 'sum',\n",
       " 'author_id_817': 'sum',\n",
       " 'author_id_818': 'sum',\n",
       " 'author_id_819': 'sum',\n",
       " 'author_id_820': 'sum',\n",
       " 'author_id_821': 'sum',\n",
       " 'author_id_823': 'sum',\n",
       " 'author_id_824': 'sum',\n",
       " 'author_id_825': 'sum',\n",
       " 'author_id_826': 'sum',\n",
       " 'author_id_827': 'sum',\n",
       " 'author_id_828': 'sum',\n",
       " 'author_id_829': 'sum',\n",
       " 'author_id_830': 'sum',\n",
       " 'author_id_831': 'sum',\n",
       " 'author_id_832': 'sum',\n",
       " 'author_id_833': 'sum',\n",
       " 'author_id_834': 'sum',\n",
       " 'author_id_835': 'sum',\n",
       " 'author_id_836': 'sum',\n",
       " 'author_id_837': 'sum',\n",
       " 'author_id_838': 'sum',\n",
       " 'author_id_839': 'sum',\n",
       " 'author_id_841': 'sum',\n",
       " 'author_id_842': 'sum',\n",
       " 'author_id_843': 'sum',\n",
       " 'author_id_844': 'sum',\n",
       " 'author_id_845': 'sum',\n",
       " 'author_id_846': 'sum',\n",
       " 'author_id_847': 'sum',\n",
       " 'author_id_848': 'sum',\n",
       " 'author_id_849': 'sum',\n",
       " 'author_id_850': 'sum',\n",
       " 'author_id_851': 'sum',\n",
       " 'author_id_852': 'sum',\n",
       " 'author_id_853': 'sum',\n",
       " 'author_id_854': 'sum',\n",
       " 'author_id_855': 'sum',\n",
       " 'author_id_856': 'sum',\n",
       " 'author_id_857': 'sum',\n",
       " 'author_id_858': 'sum',\n",
       " 'author_id_859': 'sum',\n",
       " 'author_id_860': 'sum',\n",
       " 'author_id_861': 'sum',\n",
       " 'author_id_862': 'sum',\n",
       " 'author_id_863': 'sum',\n",
       " 'author_id_864': 'sum',\n",
       " 'author_id_865': 'sum',\n",
       " 'author_id_866': 'sum',\n",
       " 'author_id_867': 'sum',\n",
       " 'author_id_868': 'sum',\n",
       " 'author_id_869': 'sum',\n",
       " 'author_id_870': 'sum',\n",
       " 'author_id_871': 'sum',\n",
       " 'author_id_875': 'sum',\n",
       " 'author_id_876': 'sum',\n",
       " 'author_id_877': 'sum',\n",
       " 'author_id_878': 'sum',\n",
       " 'author_id_879': 'sum',\n",
       " 'author_id_880': 'sum',\n",
       " 'author_id_881': 'sum',\n",
       " 'author_id_882': 'sum',\n",
       " 'author_id_883': 'sum',\n",
       " 'author_id_884': 'sum',\n",
       " 'author_id_886': 'sum',\n",
       " 'author_id_887': 'sum',\n",
       " 'author_id_888': 'sum',\n",
       " 'author_id_889': 'sum',\n",
       " 'author_id_890': 'sum',\n",
       " 'author_id_891': 'sum',\n",
       " 'author_id_892': 'sum',\n",
       " 'author_id_893': 'sum',\n",
       " 'author_id_894': 'sum',\n",
       " 'author_id_895': 'sum',\n",
       " 'author_id_896': 'sum',\n",
       " 'author_id_897': 'sum',\n",
       " 'author_id_898': 'sum',\n",
       " 'author_id_899': 'sum',\n",
       " 'author_id_900': 'sum',\n",
       " 'author_id_901': 'sum',\n",
       " 'author_id_902': 'sum',\n",
       " 'author_id_904': 'sum',\n",
       " 'author_id_905': 'sum',\n",
       " 'author_id_906': 'sum',\n",
       " 'author_id_907': 'sum',\n",
       " 'author_id_908': 'sum',\n",
       " 'author_id_909': 'sum',\n",
       " 'author_id_910': 'sum',\n",
       " 'author_id_911': 'sum',\n",
       " 'author_id_912': 'sum',\n",
       " 'author_id_913': 'sum',\n",
       " 'author_id_914': 'sum',\n",
       " 'author_id_915': 'sum',\n",
       " 'author_id_916': 'sum',\n",
       " 'author_id_917': 'sum',\n",
       " 'author_id_918': 'sum',\n",
       " 'author_id_919': 'sum',\n",
       " 'author_id_920': 'sum',\n",
       " 'author_id_921': 'sum',\n",
       " 'author_id_922': 'sum',\n",
       " 'author_id_923': 'sum',\n",
       " 'author_id_924': 'sum',\n",
       " 'author_id_925': 'sum',\n",
       " 'author_id_926': 'sum',\n",
       " 'author_id_927': 'sum',\n",
       " 'author_id_928': 'sum',\n",
       " 'author_id_929': 'sum',\n",
       " 'author_id_930': 'sum',\n",
       " 'author_id_931': 'sum',\n",
       " 'author_id_932': 'sum',\n",
       " 'author_id_933': 'sum',\n",
       " 'author_id_934': 'sum',\n",
       " 'author_id_935': 'sum',\n",
       " 'author_id_936': 'sum',\n",
       " 'author_id_937': 'sum',\n",
       " 'author_id_938': 'sum',\n",
       " 'author_id_939': 'sum',\n",
       " 'author_id_940': 'sum',\n",
       " 'author_id_941': 'sum',\n",
       " 'author_id_942': 'sum',\n",
       " 'author_id_943': 'sum',\n",
       " 'author_id_944': 'sum',\n",
       " 'author_id_945': 'sum',\n",
       " 'author_id_946': 'sum',\n",
       " 'author_id_947': 'sum',\n",
       " 'author_id_948': 'sum',\n",
       " 'author_id_949': 'sum',\n",
       " 'author_id_950': 'sum',\n",
       " 'author_id_951': 'sum',\n",
       " 'author_id_952': 'sum',\n",
       " 'author_id_953': 'sum',\n",
       " 'author_id_954': 'sum',\n",
       " 'author_id_956': 'sum',\n",
       " 'author_id_957': 'sum',\n",
       " 'author_id_960': 'sum',\n",
       " 'author_id_961': 'sum',\n",
       " 'author_id_962': 'sum',\n",
       " 'author_id_963': 'sum',\n",
       " 'author_id_964': 'sum',\n",
       " 'author_id_966': 'sum',\n",
       " 'author_id_967': 'sum',\n",
       " 'author_id_968': 'sum',\n",
       " 'author_id_969': 'sum',\n",
       " 'author_id_970': 'sum',\n",
       " 'author_id_971': 'sum',\n",
       " 'author_id_972': 'sum',\n",
       " 'author_id_973': 'sum',\n",
       " 'author_id_974': 'sum',\n",
       " 'author_id_975': 'sum',\n",
       " 'author_id_976': 'sum',\n",
       " 'author_id_977': 'sum',\n",
       " 'author_id_978': 'sum',\n",
       " 'author_id_979': 'sum',\n",
       " 'author_id_980': 'sum',\n",
       " 'author_id_981': 'sum',\n",
       " 'author_id_982': 'sum',\n",
       " 'author_id_983': 'sum',\n",
       " 'author_id_984': 'sum',\n",
       " 'author_id_985': 'sum',\n",
       " 'author_id_986': 'sum',\n",
       " 'author_id_987': 'sum',\n",
       " 'author_id_988': 'sum',\n",
       " 'author_id_989': 'sum',\n",
       " 'author_id_990': 'sum',\n",
       " 'author_id_991': 'sum',\n",
       " 'author_id_992': 'sum',\n",
       " 'author_id_993': 'sum',\n",
       " 'author_id_994': 'sum',\n",
       " 'author_id_996': 'sum',\n",
       " 'author_id_997': 'sum',\n",
       " 'author_id_998': 'sum',\n",
       " 'author_id_999': 'sum',\n",
       " 'author_id_1000': 'sum',\n",
       " 'author_id_1001': 'sum',\n",
       " 'author_id_1002': 'sum',\n",
       " 'author_id_1003': 'sum',\n",
       " 'author_id_1004': 'sum',\n",
       " 'author_id_1005': 'sum',\n",
       " 'author_id_1006': 'sum',\n",
       " 'author_id_1007': 'sum',\n",
       " 'author_id_1008': 'sum',\n",
       " 'author_id_1009': 'sum',\n",
       " 'author_id_1010': 'sum',\n",
       " 'author_id_1011': 'sum',\n",
       " 'author_id_1012': 'sum',\n",
       " 'author_id_1014': 'sum',\n",
       " 'author_id_1015': 'sum',\n",
       " 'author_id_1016': 'sum',\n",
       " 'author_id_1017': 'sum',\n",
       " 'author_id_1018': 'sum',\n",
       " 'author_id_1019': 'sum',\n",
       " 'author_id_1020': 'sum',\n",
       " 'author_id_1021': 'sum',\n",
       " 'author_id_1022': 'sum',\n",
       " 'author_id_1023': 'sum',\n",
       " 'author_id_1025': 'sum',\n",
       " 'author_id_1026': 'sum',\n",
       " 'author_id_1027': 'sum',\n",
       " 'author_id_1028': 'sum',\n",
       " 'author_id_1029': 'sum',\n",
       " 'author_id_1030': 'sum',\n",
       " 'author_id_1031': 'sum',\n",
       " 'author_id_1032': 'sum',\n",
       " 'author_id_1033': 'sum',\n",
       " 'author_id_1034': 'sum',\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_functions = {}\n",
    "\n",
    "keys = dummies.columns\n",
    "for i in keys:\n",
    "    if re.match('author_id_\\d*', i) == None:\n",
    "        agg_functions[i] = 'first'\n",
    "    else:\n",
    "        agg_functions[i] = 'sum'\n",
    "\n",
    "agg_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title_len</th>\n",
       "      <th>paper_len</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>Oral</th>\n",
       "      <th>Poster</th>\n",
       "      <th>Spotlight</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>...</th>\n",
       "      <th>author_id_10473</th>\n",
       "      <th>author_id_10474</th>\n",
       "      <th>author_id_10475</th>\n",
       "      <th>author_id_10476</th>\n",
       "      <th>author_id_10477</th>\n",
       "      <th>author_id_10478</th>\n",
       "      <th>author_id_10479</th>\n",
       "      <th>author_id_10480</th>\n",
       "      <th>author_id_10481</th>\n",
       "      <th>author_id_10482</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>21643</td>\n",
       "      <td>4.808264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>184\\n\\nTHE CAPACITY OF THE KANERVA ASSOCIATIVE...</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>16755</td>\n",
       "      <td>4.639499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>52\\n\\nSupervised Learning of Probability Distr...</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>13400</td>\n",
       "      <td>4.984227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>612\\n\\nConstrained Differential Optimization\\n...</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>25759</td>\n",
       "      <td>5.013431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>485\\n\\nTOWARDS AN ORGANIZING PRINCIPLE FOR\\nA ...</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>32874</td>\n",
       "      <td>5.024413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7234</th>\n",
       "      <td>2017</td>\n",
       "      <td>On Separability of Loss Functions, and Revisit...</td>\n",
       "      <td>7280</td>\n",
       "      <td>85</td>\n",
       "      <td>34859</td>\n",
       "      <td>4.725678</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7235</th>\n",
       "      <td>2017</td>\n",
       "      <td>Maxing and Ranking with Few Assumptions\\nMoein...</td>\n",
       "      <td>7281</td>\n",
       "      <td>39</td>\n",
       "      <td>36243</td>\n",
       "      <td>4.415865</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7236</th>\n",
       "      <td>2017</td>\n",
       "      <td>On clustering network-valued data\\n\\nSoumendu ...</td>\n",
       "      <td>7282</td>\n",
       "      <td>33</td>\n",
       "      <td>36121</td>\n",
       "      <td>4.940303</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7237</th>\n",
       "      <td>2017</td>\n",
       "      <td>A General Framework for Robust Interactive\\nLe...</td>\n",
       "      <td>7283</td>\n",
       "      <td>51</td>\n",
       "      <td>40083</td>\n",
       "      <td>4.772216</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7238</th>\n",
       "      <td>2017</td>\n",
       "      <td>Multi-view Matrix Factorization for Linear\\nDy...</td>\n",
       "      <td>7284</td>\n",
       "      <td>70</td>\n",
       "      <td>36829</td>\n",
       "      <td>4.989054</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7239 rows Ã— 9792 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                                         paper_text  paper_id  \\\n",
       "0     1987  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...         1   \n",
       "1     1987  184\\n\\nTHE CAPACITY OF THE KANERVA ASSOCIATIVE...         2   \n",
       "2     1987  52\\n\\nSupervised Learning of Probability Distr...         3   \n",
       "3     1987  612\\n\\nConstrained Differential Optimization\\n...         4   \n",
       "4     1987  485\\n\\nTOWARDS AN ORGANIZING PRINCIPLE FOR\\nA ...         5   \n",
       "...    ...                                                ...       ...   \n",
       "7234  2017  On Separability of Loss Functions, and Revisit...      7280   \n",
       "7235  2017  Maxing and Ranking with Few Assumptions\\nMoein...      7281   \n",
       "7236  2017  On clustering network-valued data\\n\\nSoumendu ...      7282   \n",
       "7237  2017  A General Framework for Robust Interactive\\nLe...      7283   \n",
       "7238  2017  Multi-view Matrix Factorization for Linear\\nDy...      7284   \n",
       "\n",
       "      title_len  paper_len  avg_word_len  Oral  Poster  Spotlight  Unknown  \\\n",
       "0            62      21643      4.808264     0       0          0        1   \n",
       "1            61      16755      4.639499     0       0          0        1   \n",
       "2            67      13400      4.984227     0       0          0        1   \n",
       "3            37      25759      5.013431     0       0          0        1   \n",
       "4            64      32874      5.024413     0       0          0        1   \n",
       "...         ...        ...           ...   ...     ...        ...      ...   \n",
       "7234         85      34859      4.725678     0       1          0        0   \n",
       "7235         39      36243      4.415865     0       1          0        0   \n",
       "7236         33      36121      4.940303     0       1          0        0   \n",
       "7237         51      40083      4.772216     0       1          0        0   \n",
       "7238         70      36829      4.989054     0       1          0        0   \n",
       "\n",
       "      ...  author_id_10473  author_id_10474  author_id_10475  author_id_10476  \\\n",
       "0     ...                0                0                0                0   \n",
       "1     ...                0                0                0                0   \n",
       "2     ...                0                0                0                0   \n",
       "3     ...                0                0                0                0   \n",
       "4     ...                0                0                0                0   \n",
       "...   ...              ...              ...              ...              ...   \n",
       "7234  ...                0                0                0                0   \n",
       "7235  ...                0                0                0                0   \n",
       "7236  ...                0                0                0                0   \n",
       "7237  ...                0                0                0                0   \n",
       "7238  ...                0                0                0                0   \n",
       "\n",
       "      author_id_10477  author_id_10478  author_id_10479  author_id_10480  \\\n",
       "0                   0                0                0                0   \n",
       "1                   0                0                0                0   \n",
       "2                   0                0                0                0   \n",
       "3                   0                0                0                0   \n",
       "4                   0                0                0                0   \n",
       "...               ...              ...              ...              ...   \n",
       "7234                0                0                0                0   \n",
       "7235                0                0                0                0   \n",
       "7236                0                0                0                0   \n",
       "7237                0                0                0                0   \n",
       "7238                0                0                0                0   \n",
       "\n",
       "      author_id_10481  author_id_10482  \n",
       "0                   0                0  \n",
       "1                   0                0  \n",
       "2                   0                0  \n",
       "3                   0                0  \n",
       "4                   0                0  \n",
       "...               ...              ...  \n",
       "7234                0                0  \n",
       "7235                0                0  \n",
       "7236                0                0  \n",
       "7237                0                0  \n",
       "7238                0                0  \n",
       "\n",
       "[7239 rows x 9792 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dummies.groupby(dummies['paper_id']).aggregate(agg_functions).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=None; y=None; tested_authors_str=None\n",
    "\n",
    "def X_y_generator(tested_authors):\n",
    "\n",
    "    \"\"\"A function to take the dataframe df and create X (features) and y (target features) for a given\n",
    "    list of authors 'tested_authors' to include in y. It also scales the features in X so they are usable \n",
    "    by the Logistic Regression model\"\"\"\n",
    "\n",
    "    global X; global y; global df; global tested_authors_str\n",
    "\n",
    "    tested_authors_str = []\n",
    "    for author in tested_authors:\n",
    "        tested_authors_str.append(f'author_id_{author}')\n",
    "    \n",
    "    exclude = tested_authors_str.__add__(['paper_id'])\n",
    "\n",
    "    X = df[df.columns.difference(exclude)]\n",
    "\n",
    "    y = df[tested_authors_str]\n",
    "\n",
    "    scaled_feat = X[X.columns.difference(['paper_text'])]\n",
    "    paper_text = pd.DataFrame(X.paper_text)\n",
    "\n",
    "    minmax = MinMaxScaler()\n",
    "    scaled_feat = pd.DataFrame(minmax.fit_transform(scaled_feat), columns=scaled_feat.columns)\n",
    "    X = scaled_feat.join(paper_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_authors = [330, 1020]\n",
    "X_y_generator(tested_authors=tested_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = None\n",
    "X_test = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "\n",
    "def vector_train_test(X, y, rand_state, stratify): \n",
    "\n",
    "    \"\"\"A function that takes two arrays X and y and splits them into a train and test set.\n",
    "    It also vectorizes the text input with TfidfVectorizer, and sets the global variables\n",
    "    X_train, X_test, y_train, y_test to the relevant sparse matrices\"\"\"\n",
    "\n",
    "    global X_train; global X_test; global y_train; global y_test\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rand_state, train_size=0.75, stratify=stratify)\n",
    "\n",
    "    other_features_train = csr_matrix(X_train[X_train.columns.difference(['paper_text'])].values)\n",
    "    other_features_test = csr_matrix(X_test[X_test.columns.difference(['paper_text'])].values)\n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "\n",
    "    X_train_vector = tfidf.fit_transform(X_train.paper_text)\n",
    "    X_test_vector = tfidf.transform(X_test.paper_text)\n",
    "\n",
    "    X_train = hstack([other_features_train, X_train_vector])\n",
    "    X_test = hstack([other_features_test, X_test_vector])\n",
    "\n",
    "    X_train = np.asarray(csr_matrix.todense(X_train))\n",
    "    X_test = np.asarray(csr_matrix.todense(X_test))\n",
    "    y_train = pd.DataFrame.to_numpy(y_train)\n",
    "    y_test = pd.DataFrame.to_numpy(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_train_test(X=X, y=y, rand_state=11, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C=1, max_iter=1000, class_weight='balanced')\n",
    "\n",
    "multi_output_LR = MultiOutputClassifier(LR)\n",
    "multi_output_LR.fit(X_train, y_train)\n",
    "\n",
    "prediction = multi_output_LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss is: 0.016574585635359115\n",
      "F1 score is: 0.37168603891863655\n"
     ]
    }
   ],
   "source": [
    "h_loss = hamming_loss(y_test, prediction)\n",
    "f_score = f1_score(y_test, prediction, average='weighted')\n",
    "print('Hamming loss is:', h_loss)\n",
    "print('F1 score is:', f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_matricies_test = multilabel_confusion_matrix(y_test, prediction)\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "for i, cm_test in enumerate(c_matricies_test):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_test)\n",
    "    disp.plot(ax=ax[i])\n",
    "    disp.ax_.set_title(f'{tested_authors_str[i]}')\n",
    "    disp.im_.colorbar.remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.95828328, 0.04171672],\n",
       "        [0.92313038, 0.07686962],\n",
       "        [0.98882745, 0.01117255],\n",
       "        ...,\n",
       "        [0.96156796, 0.03843204],\n",
       "        [0.95457265, 0.04542735],\n",
       "        [0.97013984, 0.02986016]]),\n",
       " array([[0.96944742, 0.03055258],\n",
       "        [0.98308021, 0.01691979],\n",
       "        [0.99390663, 0.00609337],\n",
       "        ...,\n",
       "        [0.97042894, 0.02957106],\n",
       "        [0.72529134, 0.27470866],\n",
       "        [0.96058439, 0.03941561]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba = multi_output_LR.predict_proba(X_test)\n",
    "\n",
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_330</th>\n",
       "      <th>author_id_1020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041717</td>\n",
       "      <td>0.030553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076870</td>\n",
       "      <td>0.016920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011173</td>\n",
       "      <td>0.006093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051007</td>\n",
       "      <td>0.075532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.186474</td>\n",
       "      <td>0.075815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>0.037872</td>\n",
       "      <td>0.024095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>0.050734</td>\n",
       "      <td>0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>0.038432</td>\n",
       "      <td>0.029571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>0.045427</td>\n",
       "      <td>0.274709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>0.029860</td>\n",
       "      <td>0.039416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1810 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      author_id_330  author_id_1020\n",
       "0          0.041717        0.030553\n",
       "1          0.076870        0.016920\n",
       "2          0.011173        0.006093\n",
       "3          0.051007        0.075532\n",
       "4          0.186474        0.075815\n",
       "...             ...             ...\n",
       "1805       0.037872        0.024095\n",
       "1806       0.050734        0.019300\n",
       "1807       0.038432        0.029571\n",
       "1808       0.045427        0.274709\n",
       "1809       0.029860        0.039416\n",
       "\n",
       "[1810 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df = pd.DataFrame(data=[proba[0][:, 1], proba[1][:, 1]], index=tested_authors_str).T\n",
    "proba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_330</th>\n",
       "      <th>author_id_1020</th>\n",
       "      <th>True_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041717</td>\n",
       "      <td>0.030553</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076870</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011173</td>\n",
       "      <td>0.006093</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051007</td>\n",
       "      <td>0.075532</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.186474</td>\n",
       "      <td>0.075815</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>0.037872</td>\n",
       "      <td>0.024095</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>0.050734</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>0.038432</td>\n",
       "      <td>0.029571</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>0.045427</td>\n",
       "      <td>0.274709</td>\n",
       "      <td>0,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>0.029860</td>\n",
       "      <td>0.039416</td>\n",
       "      <td>0,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1810 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      author_id_330  author_id_1020 True_Label\n",
       "0          0.041717        0.030553        0,0\n",
       "1          0.076870        0.016920        0,0\n",
       "2          0.011173        0.006093        0,0\n",
       "3          0.051007        0.075532        0,0\n",
       "4          0.186474        0.075815        0,0\n",
       "...             ...             ...        ...\n",
       "1805       0.037872        0.024095        0,0\n",
       "1806       0.050734        0.019300        0,0\n",
       "1807       0.038432        0.029571        0,0\n",
       "1808       0.045427        0.274709        0,1\n",
       "1809       0.029860        0.039416        0,0\n",
       "\n",
       "[1810 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df['True_Label_list'] = y_test.tolist()\n",
    "proba_df['True_Label'] = [','.join(map(str, l)) for l in proba_df['True_Label_list']]\n",
    "proba_df.drop('True_Label_list', axis=1, inplace=True)\n",
    "proba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=proba_df['author_id_330'][proba_df['True_Label']=='0,0'], y=proba_df['author_id_1020'][proba_df['True_Label']=='0,0'], color='blue', alpha=0.25, label='Neither Author')\n",
    "plt.scatter(x=proba_df['author_id_330'][proba_df['True_Label']=='1,0'], y=proba_df['author_id_1020'][proba_df['True_Label']=='1,0'], color='green', label='author_id_330')\n",
    "plt.scatter(x=proba_df['author_id_330'][proba_df['True_Label']=='0,1'], y=proba_df['author_id_1020'][proba_df['True_Label']=='0,1'], color='red', label='author_id_1020')\n",
    "plt.scatter(x=proba_df['author_id_330'][proba_df['True_Label']=='1,1'], y=proba_df['author_id_1020'][proba_df['True_Label']=='1,1'], color='purple', label='Both Authors')\n",
    "plt.title('Probability a Paper Belongs to a Given Author')\n",
    "plt.xlabel('Probability to be author id 330')\n",
    "plt.ylabel('Probability to be author id 1020')\n",
    "plt.legend(title='True Labels', fontsize='small', loc=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[330, 1472, 178, 121, 1020]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_authors = top_authors.author_id[0:5].to_list()\n",
    "\n",
    "ten_authors = top_authors.author_id[0:10].to_list()\n",
    "\n",
    "fifteen_authors = top_authors.author_id[0:15].to_list()\n",
    "\n",
    "five_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_list_of_lists = [five_authors, ten_authors, fifteen_authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19244/4132577552.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mmulti_output_LR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiOutputClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mmulti_output_LR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# Predicting on the train and test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\sklearn\\multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \"\"\"\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\sklearn\\multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mfit_params_validated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m    203\u001b[0m             delayed(_fit_estimator)(\n\u001b[0;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_validated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\sklearn\\multioutput.py\u001b[0m in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1136\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m   1139\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1072\u001b[0m         )\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1075\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m             _assert_all_finite(\n\u001b[0m\u001b[0;32m    900\u001b[0m                 \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;31m# safely to reduce dtype induced overflows.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m\"fc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_safe_accumulator_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36m_safe_accumulator_op\u001b[1;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    898\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2296\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2298\u001b[1;33m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[0;32m   2299\u001b[0m                           initial=initial, where=where)\n\u001b[0;32m   2300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\William\\anaconda3\\envs\\Springboard_Capstone_1\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initializing a dictionary with keys corresponding to the hyperparameters I am testing, \n",
    "# as well as my results on the train and test sets\n",
    "MOC_dict = {'Num_authors_tested' : [],\n",
    "            'F1_score_train_avg': [],\n",
    "            'F1_score_test_avg':[]}\n",
    "\n",
    "run = 0\n",
    "\n",
    "for auth_list in authors_list_of_lists:\n",
    "\n",
    "    # Appending the # of authors tested to the dictionary\n",
    "    MOC_dict['Num_authors_tested'].append(len(auth_list))\n",
    "\n",
    "    # Creating the X and y feature variables to be used for this set of authors\n",
    "    X_y_generator(tested_authors=auth_list)\n",
    "\n",
    "    F1_train_scores = []\n",
    "    F1_test_scores = []\n",
    "\n",
    "    for random_state in random_states:\n",
    "\n",
    "        # Counting what iteration I am on\n",
    "        print(run)\n",
    "        run += 1\n",
    "\n",
    "        # Generating X_train, X_test, y_train, y_test\n",
    "        vector_train_test(X=X, y=y, rand_state=random_state, stratify=None)\n",
    "\n",
    "        # Creating the MOC-LR model, fitting it on the train set\n",
    "        LR = LogisticRegression(C=1, max_iter=1000, class_weight='balanced')\n",
    "\n",
    "        multi_output_LR = MultiOutputClassifier(LR)\n",
    "        multi_output_LR.fit(X_train, y_train)\n",
    "\n",
    "        # Predicting on the train and test sets\n",
    "        pred_train = multi_output_LR.predict(X_train)\n",
    "        pred_test = multi_output_LR.predict(X_test)\n",
    "        \n",
    "        # Finding the average f1_score for this iteration\n",
    "        f_score_train = f1_score(y_train, pred_train, average='weighted')\n",
    "        f_score_test = f1_score(y_test, pred_test, average='weighted')\n",
    "\n",
    "        # Appending this score to the list outside of the loop\n",
    "        F1_train_scores.append(f_score_train)\n",
    "        F1_test_scores.append(f_score_test)\n",
    "\n",
    "    # Appending the scores to the dictionary\n",
    "    MOC_dict['F1_score_train_avg'].append(mean(F1_train_scores))\n",
    "    MOC_dict['F1_score_test_avg'].append(mean(F1_test_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_authors_tested</th>\n",
       "      <th>F1_score_train_avg</th>\n",
       "      <th>F1_score_test_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.809592</td>\n",
       "      <td>0.464702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.825318</td>\n",
       "      <td>0.456004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.789369</td>\n",
       "      <td>0.430158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num_authors_tested  F1_score_train_avg  F1_score_test_avg\n",
       "1                  10            0.809592           0.464702\n",
       "2                  15            0.825318           0.456004\n",
       "0                   5            0.789369           0.430158"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOC_HPtable = pd.DataFrame.from_dict(MOC_dict)\n",
    "MOC_HPtable.sort_values(by='F1_score_test_avg', ascending=False, inplace=True)\n",
    "MOC_HPtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_list_of_lists = [five_authors, ten_authors, fifteen_authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Initializing a dictionary with keys corresponding to the hyperparameters I am testing, \n",
    "# as well as my results on the train and test sets\n",
    "CC_dict = {'Num_authors_tested' : [],\n",
    "            'F1_score_train_avg': [],\n",
    "            'F1_score_test_avg':[]}\n",
    "\n",
    "run = 0\n",
    "\n",
    "for auth_list in authors_list_of_lists:\n",
    "\n",
    "    # Appending the # of authors tested to the dictionary\n",
    "    CC_dict['Num_authors_tested'].append(len(auth_list))\n",
    "\n",
    "    # Creating the X and y feature variables to be used for this set of authors\n",
    "    X_y_generator(tested_authors=auth_list)\n",
    "\n",
    "    F1_train_scores = []\n",
    "    F1_test_scores = []\n",
    "\n",
    "    for random_state in random_states:\n",
    "\n",
    "        # Counting what iteration I am on\n",
    "        print(run)\n",
    "        run += 1\n",
    "\n",
    "        # Generating X_train, X_test, y_train, y_test\n",
    "        vector_train_test(X=X, y=y, rand_state=random_state, stratify=None)\n",
    "\n",
    "        # Creating the MOC-LR model, fitting it on the train set\n",
    "        LR = LogisticRegression(C=1, max_iter=1000, class_weight='balanced')\n",
    "\n",
    "        chain = ClassifierChain(LR, order='random', random_state=random_state)\n",
    "        multi_output_LR.fit(X_train, y_train)\n",
    "\n",
    "        # Predicting on the train and test sets\n",
    "        pred_train = multi_output_LR.predict(X_train)\n",
    "        pred_test = multi_output_LR.predict(X_test)\n",
    "        \n",
    "        # Finding the average f1_score for this iteration\n",
    "        f_score_train = f1_score(y_train, pred_train, average='weighted')\n",
    "        f_score_test = f1_score(y_test, pred_test, average='weighted')\n",
    "\n",
    "        # Appending this score to the list outside of the loop\n",
    "        F1_train_scores.append(f_score_train)\n",
    "        F1_test_scores.append(f_score_test)\n",
    "\n",
    "    # Appending the scores to the dictionary\n",
    "    CC_dict['F1_score_train_avg'].append(mean(F1_train_scores))\n",
    "    CC_dict['F1_score_test_avg'].append(mean(F1_test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_authors_tested</th>\n",
       "      <th>F1_score_train_avg</th>\n",
       "      <th>F1_score_test_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.809592</td>\n",
       "      <td>0.464702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.789369</td>\n",
       "      <td>0.430158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num_authors_tested  F1_score_train_avg  F1_score_test_avg\n",
       "1                  10            0.809592           0.464702\n",
       "0                   5            0.789369           0.430158"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CC_HPtable = pd.DataFrame.from_dict(CC_dict)\n",
    "CC_HPtable.sort_values(by='F1_score_test_avg', ascending=False, inplace=True)\n",
    "CC_HPtable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Springboard_Capstone_1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "918dc82fcda072602f7dedc1715dd52bd51c73a6bbc48592bc491021bad55eb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
