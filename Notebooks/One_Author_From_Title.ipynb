{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the first modeling I will do for this project. While it's not likely to be very predictive, I'm going to try to predict the authorship of a paper based only on its title, and only for the second most prolific author in the dataset. This will hopefully allow me to gain a familiarity with some of the tools for NLP modeling, and check some initial strategies to see what works and what doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_and_authors = pd.read_csv('E:/OtherCodeProjects/Springboard Capstone Projects/Springboard-Capstone-1-Data/papers_and_authors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the corrected dataset, with each paper duplicated for each author it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "      <td>100</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "      <td>100</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                              title event_type  \\\n",
       "0  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "2  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "3  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "4  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "2  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "3  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "4  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  paper_id  author_id  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...         1          1  \n",
       "1  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...         1          2  \n",
       "2  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...        10         14  \n",
       "3  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...       100        155  \n",
       "4  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...       100         54  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_and_authors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 20843 entries as I would expect, 5 more than the initial uncorrected dataset that was missing three papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20843 entries, 0 to 20842\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   year        20843 non-null  int64 \n",
      " 1   title       20843 non-null  object\n",
      " 2   event_type  8156 non-null   object\n",
      " 3   pdf_name    20843 non-null  object\n",
      " 4   abstract    20843 non-null  object\n",
      " 5   paper_text  20843 non-null  object\n",
      " 6   paper_id    20843 non-null  int64 \n",
      " 7   author_id   20843 non-null  int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "papers_and_authors.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project I'm going to remove all of the features other than title and the author id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  author_id\n",
       "0  Self-Organization of Associative Database and ...          1\n",
       "1  Self-Organization of Associative Database and ...          2\n",
       "2  A Mean Field Theory of Layer IV of Visual Cort...         14\n",
       "3  Storing Covariance by the Associative Long-Ter...        155\n",
       "4  Storing Covariance by the Associative Long-Ter...         54"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_auth_title = papers_and_authors.drop(['year', 'event_type', 'pdf_name', 'abstract', 'paper_text', 'paper_id'], axis=1)\n",
    "only_auth_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I need an actual \"target feature\" for my model, in this case if the paper was written by Bernhard Scholkopf, author_id 1472. This function detects if his author id is in the appropriate column, and returns a 1 if it is and a 0 if it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernhard_detector(row):\n",
    "    if row['author_id'] == 1472:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying this function to create a new 'is_jordan' column, with the appropriate 1 or 0 as the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author_id</th>\n",
       "      <th>is_bernhard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  author_id  is_bernhard\n",
       "0  Self-Organization of Associative Database and ...          1            0\n",
       "1  Self-Organization of Associative Database and ...          2            0\n",
       "2  A Mean Field Theory of Layer IV of Visual Cort...         14            0\n",
       "3  Storing Covariance by the Associative Long-Ter...        155            0\n",
       "4  Storing Covariance by the Associative Long-Ter...         54            0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_auth_title['is_bernhard'] = only_auth_title.apply(lambda row: bernhard_detector(row), axis=1)\n",
    "only_auth_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying this dataframe for his author id I see that, as expected from the previous notebook, he wrote 62 papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(only_auth_title.query('author_id == 1472'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can drop the author_id column entirely. I also need to get rid of duplicate papers, but some of the duplicated papers he wrote or co-wrote, and I need to keep those entries where 'is_bernhard' == 1. I sort the papers he wrote up to the top of the dataframe and use .drop_duplicates with keep='first' in order to remove duplicates that aren't his. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7241"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_bernhard = only_auth_title.drop('author_id', axis=1)\n",
    "is_bernhard.sort_values(by='is_bernhard', ascending=False, inplace=True)\n",
    "is_bernhard.drop_duplicates(subset='title', keep='first', inplace=True)\n",
    "len(is_bernhard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By double checking I can see that he still has 62 papers listed as his."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(is_bernhard.query('is_bernhard == 1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having written 62 papers out of ~7000, he is responsible for about ~0.8% of the dataset as a whole, making this a very imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.991438\n",
       "1    0.008562\n",
       "Name: is_bernhard, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_bernhard.is_bernhard.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I split my features into X: the title still in plaintext as a dataframe, and y: the 'is_bernhard' column flattened into a 1-dimentional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = is_bernhard['title'].to_frame()\n",
    "y = is_bernhard['is_bernhard'].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating my train and test split, with the train size set to 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=21, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can change the title's plaintext into something actually usable by a model. In this case I will be using scikit-learn's TfidfVectorizer, which is essentially an advanced \"bag of words\" representation. Each word in each title is made into a feature, with the values being the number of times that word appears in that title. Then the values are normalized across all of the words in all of the titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, I will fit and transform on the train set, and only transform the test set. The shape tells me I have 5430 titles in the train set, as expected, and 4865 columns each representing a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5430, 4865)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_train = tfidf.fit_transform(X_train.title)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code shows the statistics of the vectorized titles. While most words aren't in a given title, I can see that the proper normalized values are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>17</th>\n",
       "      <th>1993</th>\n",
       "      <th>1d</th>\n",
       "      <th>25</th>\n",
       "      <th>2d</th>\n",
       "      <th>360</th>\n",
       "      <th>3d</th>\n",
       "      <th>3n2</th>\n",
       "      <th>40</th>\n",
       "      <th>...</th>\n",
       "      <th>ying</th>\n",
       "      <th>yosida</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroth</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zip</th>\n",
       "      <th>zype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005616</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>0.006377</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.006699</td>\n",
       "      <td>0.009963</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>0.014007</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>0.005735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.413822</td>\n",
       "      <td>0.604786</td>\n",
       "      <td>0.359673</td>\n",
       "      <td>0.373624</td>\n",
       "      <td>0.396649</td>\n",
       "      <td>0.483157</td>\n",
       "      <td>0.469903</td>\n",
       "      <td>0.580021</td>\n",
       "      <td>0.429781</td>\n",
       "      <td>0.298990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447406</td>\n",
       "      <td>0.493604</td>\n",
       "      <td>0.514689</td>\n",
       "      <td>0.369483</td>\n",
       "      <td>0.529268</td>\n",
       "      <td>0.477575</td>\n",
       "      <td>0.360781</td>\n",
       "      <td>0.442530</td>\n",
       "      <td>0.436726</td>\n",
       "      <td>0.422571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 4865 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               000           17         1993           1d           25  \\\n",
       "count  5430.000000  5430.000000  5430.000000  5430.000000  5430.000000   \n",
       "mean      0.000076     0.000111     0.000066     0.000069     0.000073   \n",
       "std       0.005616     0.008207     0.004881     0.005070     0.005383   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.413822     0.604786     0.359673     0.373624     0.396649   \n",
       "\n",
       "                2d          360           3d          3n2           40  ...  \\\n",
       "count  5430.000000  5430.000000  5430.000000  5430.000000  5430.000000  ...   \n",
       "mean      0.000539     0.000087     0.001925     0.000079     0.000055  ...   \n",
       "std       0.015093     0.006377     0.027300     0.005832     0.004057  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       0.483157     0.469903     0.580021     0.429781     0.298990  ...   \n",
       "\n",
       "              ying       yosida          you        young         your  \\\n",
       "count  5430.000000  5430.000000  5430.000000  5430.000000  5430.000000   \n",
       "mean      0.000082     0.000091     0.000231     0.000068     0.000167   \n",
       "std       0.006072     0.006699     0.009963     0.005014     0.008807   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.447406     0.493604     0.514689     0.369483     0.529268   \n",
       "\n",
       "              zero       zeroth         zeta          zip         zype  \n",
       "count  5430.000000  5430.000000  5430.000000  5430.000000  5430.000000  \n",
       "mean      0.000462     0.000066     0.000158     0.000080     0.000078  \n",
       "std       0.014007     0.004896     0.008239     0.005927     0.005735  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       0.477575     0.360781     0.442530     0.436726     0.422571  \n",
       "\n",
       "[8 rows x 4865 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array = X_train.toarray()\n",
    "df_X_train = pd.DataFrame(X_train_array, columns=tfidf.get_feature_names_out())\n",
    "df_X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I only transform on the test set. It still has the same number of features as the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1811, 4865)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tfidf.transform(X_test.title)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these models I will only be using a simple logistic regression model, as this is more about establishing a baseline of performance than finding the absolute best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I fit on the train set and predict the test set, with no additional parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=21)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has an accuracy of almost 99%, but an AUC of exactly 0.5 and a 0 for a recall score. Plotting the confusion matrix confirms that this model simply predicted that Bernhard wrote none of the papers. Obviously this isn't what I'm looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9906129210381005\n",
      "AUC: 0.5\n",
      "Recall score: 0.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = lr.score(X_test, y_test)\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Accuracy:', accuracy)\n",
    "print('AUC:', auc)\n",
    "print('Recall score:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I tried using class weights, in this case an incorrect guess on a Bernhard paper is penalized 99x more harshly than on another paper. Everything else is exactly the same as the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {0:1, 1:99}\n",
    "lr2 = LogisticRegression(random_state=21, class_weight=weights)\n",
    "lr2.fit(X_train, y_train)\n",
    "predictions2 = lr2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the model scoring methods, I can see that this model is slightly better than the previous one, but not amazing by any means. 4/17 papers he wrote were sucessfully predicted, along with 24 false positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9795692987299834\n",
      "AUC: 0.6109580956128271\n",
      "Recall score: 0.23529411764705882\n"
     ]
    }
   ],
   "source": [
    "accuracy2 = lr2.score(X_test, y_test)\n",
    "auc2 = roc_auc_score(y_test, predictions2)\n",
    "recall2 = recall_score(y_test, predictions2)\n",
    "print('Accuracy:', accuracy2)\n",
    "print('AUC:', auc2)\n",
    "print('Recall score:', recall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm2 = confusion_matrix(y_test, predictions2)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, I was curious to see if I was overfitting, so I repeated the above test but predicted on the train data instead of the test data. This seem s like it could be overfitting, but I will need cross validation to check. I will do these checks in a later notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2_train = lr2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9915285451197053\n",
      "AUC: 0.9957288765088208\n",
      "Recall score: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy2_train = lr2.score(X_train, y_train)\n",
    "auc2_train = roc_auc_score(y_train, predictions2_train)\n",
    "recall2_train = recall_score(y_train, predictions2_train)\n",
    "print('Accuracy:', accuracy2_train)\n",
    "print('AUC:', auc2_train)\n",
    "print('Recall score:', recall2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm2_train = confusion_matrix(y_train, predictions2_train)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm2_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I wanted to try oversampling and undersampling as methods. I created a new train/test split so that I could oversample or undersample it accordingly. This is the \"oversample\" split, with the same random state as the last split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over, X_test_over, y_train_over, y_test_over = \\\n",
    "    train_test_split(X, y, random_state=21, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the actual oversampling. I only oversample the train set, and leave the test set as it was. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(random_state=21)\n",
    "\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again TfidfVectorizing the data, the shapes indicate that our train set now has 10,770 papers in it, with many being duplicates of Bernhard's papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10770, 4865)\n",
      "(1811, 4865)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_over = tfidf.fit_transform(X_train_over.title)\n",
    "X_test_over = tfidf.transform(X_test_over.title)\n",
    "\n",
    "print(X_train_over.shape)\n",
    "print(X_test_over.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fitting the Logistic regression model to it, then predicting on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_over = LogisticRegression(random_state=21)\n",
    "lr_over.fit(X_train_over, y_train_over)\n",
    "predictions_over = lr_over.predict(X_test_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's scores show that this model performed worse than the weighted example, with only 2/17 papers predicted. It's possible that this is due to some random variance, however, so cross validation will again be necissary to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9784649364991718\n",
      "AUC: 0.5521345662010624\n",
      "Recall score: 0.11764705882352941\n"
     ]
    }
   ],
   "source": [
    "accuracy_over = lr_over.score(X_test_over, y_test_over)\n",
    "auc_over = roc_auc_score(y_test_over, predictions_over)\n",
    "recall_over = recall_score(y_test_over, predictions_over)\n",
    "print('Accuracy:', accuracy_over)\n",
    "print('AUC:', auc_over)\n",
    "print('Recall score:', recall_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_over = confusion_matrix(y_test_over, predictions_over)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm_over)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the undersampling split, again with the same random state as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_under, X_test_under, y_train_under, y_test_under = \\\n",
    "    train_test_split(X, y, random_state=21, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again only undersampling on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(random_state=21)\n",
    "\n",
    "X_train_under, y_train_under = undersample.fit_resample(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizing the titles, the shapes indicate that only 90 papers remain in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 391)\n",
      "(1811, 391)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_under = tfidf.fit_transform(X_train_under.title)\n",
    "X_test_under = tfidf.transform(X_test_under.title)\n",
    "\n",
    "print(X_train_under.shape)\n",
    "print(X_test_under.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the LogisticRegression model to the undersampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_under = LogisticRegression(random_state=21)\n",
    "lr_under.fit(X_train_under, y_train_under)\n",
    "predictions_under = lr_under.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores here show a marked difference to the previous ones. The accuracy has tanked, while recall score has gone way up to over 50%. The overall AUC remains around the same as the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6686913307564881\n",
      "AUC: 0.6288445143943866\n",
      "Recall score: 0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "accuracy_under = lr_under.score(X_test_under, y_test_under)\n",
    "auc_under = roc_auc_score(y_test_under, predictions_under)\n",
    "recall_under = recall_score(y_test_under, predictions_under)\n",
    "print('Accuracy:', accuracy_under)\n",
    "print('AUC:', auc_under)\n",
    "print('Recall score:', recall_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix indicates that there are now a huge number of false positives, around half the size of the true negatives. The model was able to predict 10/17 of his papers, but overall this seems like a step back, and it's possible I did something incorrectly while undersampling the data. Or undersampling is just not an appropriate method for this type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_under = confusion_matrix(y_test_under, predictions_under)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm_under)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One strategy I should have used was the \"stratify\" parameter in train_test_split. This ensures that the ratio of positive and negative cases remains the same across the train and test splits, and is very useful on highly imbalanced datasets. I will use it in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X, y, random_state=21, train_size=0.75, stratify=y)\n",
    "\n",
    "print(y_test_t.tolist().count(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Springboard_Capstone_1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "918dc82fcda072602f7dedc1715dd52bd51c73a6bbc48592bc491021bad55eb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
