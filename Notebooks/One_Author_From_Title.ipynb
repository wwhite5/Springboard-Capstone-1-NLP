{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the first modeling I will do for this project. While it's not likely to be very predictive, I'm going to try to predict the authorship of a paper based only on its title, and only for the most prolific author in the dataset. This will hopefully allow me to gain a familiarity with some of the tools for NLP modeling, and check som einitial strategies to see what works and what doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_and_authors = pd.read_csv('E:/OtherCodeProjects/Springboard Capstone Projects/Springboard-Capstone-1-Data/papers_and_authors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the corrected dataset, with each paper duplicated for each author it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "      <td>100</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "      <td>100</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                              title event_type  \\\n",
       "0  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "2  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "3  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "4  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "2  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "3  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "4  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  paper_id  author_id  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...         1          1  \n",
       "1  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...         1          2  \n",
       "2  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...        10         14  \n",
       "3  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...       100        155  \n",
       "4  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...       100         54  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_and_authors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 20843 entries as I would expect, 5 more than the initial uncorrected dataset that was missing three papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20843 entries, 0 to 20842\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   year        20843 non-null  int64 \n",
      " 1   title       20843 non-null  object\n",
      " 2   event_type  8156 non-null   object\n",
      " 3   pdf_name    20843 non-null  object\n",
      " 4   abstract    20843 non-null  object\n",
      " 5   paper_text  20843 non-null  object\n",
      " 6   paper_id    20843 non-null  int64 \n",
      " 7   author_id   20843 non-null  int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "papers_and_authors.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project I'm going to remove all of the features other than title and the author id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  author_id\n",
       "0  Self-Organization of Associative Database and ...          1\n",
       "1  Self-Organization of Associative Database and ...          2\n",
       "2  A Mean Field Theory of Layer IV of Visual Cort...         14\n",
       "3  Storing Covariance by the Associative Long-Ter...        155\n",
       "4  Storing Covariance by the Associative Long-Ter...         54"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_auth_title = papers_and_authors.drop(['year', 'event_type', 'pdf_name', 'abstract', 'paper_text', 'paper_id'], axis=1)\n",
    "only_auth_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I need an actual \"target feature\" for my model, in this case if the paper was written by Michael I. Jordan, author_id 330. This function detects if his author id is in the appropriate column, and returns a 1 if it is and a 0 if it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jordan_detector(row):\n",
    "    if row['author_id'] == 330:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying this function to create a new 'is_jordan' column, with the appropriate 1 or 0 as the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author_id</th>\n",
       "      <th>is_jordan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  author_id  is_jordan\n",
       "0  Self-Organization of Associative Database and ...          1          0\n",
       "1  Self-Organization of Associative Database and ...          2          0\n",
       "2  A Mean Field Theory of Layer IV of Visual Cort...         14          0\n",
       "3  Storing Covariance by the Associative Long-Ter...        155          0\n",
       "4  Storing Covariance by the Associative Long-Ter...         54          0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_auth_title['is_jordan'] = only_auth_title.apply(lambda row: jordan_detector(row), axis=1)\n",
    "only_auth_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying this dataframe for his author id I see that, as expected from the previous notebook, he wrote 79 papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(only_auth_title.query('author_id == 330'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can drop the author_id column entirely. I also need to get rid of duplicate papers, but some of the duplicated papers wrote or co-wrote, and I need to keep those entries where 'is_jordan' == 1. I sort the papers he wrote up to the top of the dataframe and use .drop_duplicates with keep='first' in order to remove duplicates that aren't his. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7241"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_jordan = only_auth_title.drop('author_id', axis=1)\n",
    "is_jordan.sort_values(by='is_jordan', ascending=False, inplace=True)\n",
    "is_jordan.drop_duplicates(subset='title', keep='first', inplace=True)\n",
    "len(is_jordan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By double checking I can see that he still has 79 papers listed as his."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(is_jordan.query('is_jordan == 1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having written 79 papers out of ~7000, he is responsible for about ~1% of the dataset as a whole, making this a very imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.98909\n",
       "1    0.01091\n",
       "Name: is_jordan, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_jordan.is_jordan.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I split my features into X: the title still in plaintext as a dataframe, and y: the 'is_jordan' column flattened into a 1-dimentional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = is_jordan['title'].to_frame()\n",
    "y = is_jordan['is_jordan'].values.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating my train and test split, with the train size set to 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=21, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can change the title's plaintext into something actually usable by a model. In this case I will be using scikit-learn's TfidfVectorizer, which is essentially an advanced \"bag of words\" representation. Each word in each title is made into a feature, with the values being the number of times that word appears in that title. Then the values are normalized across all of the words in all of the titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, I will fit and transform on the train set, and only transform the test set. The shape tells me I have 5430 titles in the train set, as expected, and 4854 columns each representing a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5430, 4854)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_train = tfidf.fit_transform(X_train.title)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code shows the statistics of the vectorized titles. While most words aren't in a given title, I can see that the proper normalized values are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>1993</th>\n",
       "      <th>1d</th>\n",
       "      <th>25</th>\n",
       "      <th>2d</th>\n",
       "      <th>360</th>\n",
       "      <th>3d</th>\n",
       "      <th>3n2</th>\n",
       "      <th>40</th>\n",
       "      <th>5d</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>zag</th>\n",
       "      <th>zap</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroth</th>\n",
       "      <th>zeta</th>\n",
       "      <th>zig</th>\n",
       "      <th>zip</th>\n",
       "      <th>zype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "      <td>5430.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.015122</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>0.026184</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.009418</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.013042</td>\n",
       "      <td>0.014882</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>0.006424</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.005726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.411016</td>\n",
       "      <td>0.363875</td>\n",
       "      <td>0.376044</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.476690</td>\n",
       "      <td>0.470529</td>\n",
       "      <td>0.520284</td>\n",
       "      <td>0.428568</td>\n",
       "      <td>0.297751</td>\n",
       "      <td>0.450327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366642</td>\n",
       "      <td>0.515761</td>\n",
       "      <td>0.473408</td>\n",
       "      <td>0.961032</td>\n",
       "      <td>0.470466</td>\n",
       "      <td>0.354411</td>\n",
       "      <td>0.443900</td>\n",
       "      <td>0.473408</td>\n",
       "      <td>0.431109</td>\n",
       "      <td>0.421914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 4854 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               000         1993           1d           25           2d  \\\n",
       "count  5430.000000  5430.000000  5430.000000  5430.000000  5430.000000   \n",
       "mean      0.000076     0.000067     0.000069     0.000073     0.000540   \n",
       "std       0.005578     0.004938     0.005103     0.005361     0.015122   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.411016     0.363875     0.376044     0.395056     0.476690   \n",
       "\n",
       "               360           3d          3n2           40           5d  ...  \\\n",
       "count  5430.000000  5430.000000  5430.000000  5430.000000  5430.000000  ...   \n",
       "mean      0.000087     0.001820     0.000079     0.000055     0.000083  ...   \n",
       "std       0.006385     0.026184     0.005816     0.004041     0.006111  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       0.470529     0.520284     0.428568     0.297751     0.450327  ...   \n",
       "\n",
       "             young         your          zag          zap         zero  \\\n",
       "count  5430.000000  5430.000000  5430.000000  5430.000000  5430.000000   \n",
       "mean      0.000068     0.000215     0.000087     0.000177     0.000531   \n",
       "std       0.004976     0.009418     0.006424     0.013042     0.014882   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.366642     0.515761     0.473408     0.961032     0.470466   \n",
       "\n",
       "            zeroth         zeta          zig          zip         zype  \n",
       "count  5430.000000  5430.000000  5430.000000  5430.000000  5430.000000  \n",
       "mean      0.000065     0.000159     0.000087     0.000079     0.000078  \n",
       "std       0.004810     0.008277     0.006424     0.005850     0.005726  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       0.354411     0.443900     0.473408     0.431109     0.421914  \n",
       "\n",
       "[8 rows x 4854 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array = X_train.toarray()\n",
    "df_X_train = pd.DataFrame(X_train_array, columns=tfidf.get_feature_names_out())\n",
    "df_X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I only transform on the test set. It still has the same number of features as the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1811, 4854)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tfidf.transform(X_test.title)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these models I will only be using a simple logistic regression model, as this is more about establishing a baseline of performance than finding the absolute best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I fit on the train set and predict the test set, with no additional parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=21)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has an accuracy of almost 99%, but an AUC of exactly 0.5 and a 0 for a recall score. Plotting the confusion matrix confirms that this model simply predicted that Jordan wrote none of the papers. Obviously this isn't what I'm looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9895085588072888\n",
      "AUC: 0.5\n",
      "Recall score: 0.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = lr.score(X_test, y_test)\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Accuracy:', accuracy)\n",
    "print('AUC:', auc)\n",
    "print('Recall score:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAEGCAYAAABhHPB4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQDUlEQVR4nO3de5hVdbnA8e/L4CQmqeWlI6MJqBCYKUJ6Qs0sTRMxO2rSTcK00pN1PGqe51h2l7RONzKl8sjp4i01xbv1lLeDcbFE8wIolAymoKVQ9qDDe/6YHzjiMGw8rL24fD/Pw8Nea+/Z690zz/OdtdbsS2QmktSr7gEkrRuMgSTAGEgqjIEkwBhIKnrXPUBX0btPRmvfusfQGtjzjTvWPYLWwB//OI9FixZFd9etWzFo7curBh1T9xhaA3f9dkLdI2gNjNx7+Cqv8zBBEmAMJBXGQBJgDCQVxkASYAwkFcZAEmAMJBXGQBJgDCQVxkASYAwkFcZAEmAMJBXGQBJgDCQVxkASYAwkFcZAEmAMJBXGQBJgDCQVxkASYAwkFcZAEmAMJBXGQBJgDCQVxkASYAwkFcZAEmAMJBXGQBJgDCQVxkASYAwkFcZAEmAMJBXGQBJgDCQVxkASYAwkFcZAEmAMJBXGQBJgDCQVxkASYAwkFcZAEgC96x5gfXTB2R/g0P13Y+HTixl+9FcB+PH4j7DLTtsBsGXfPvx18XPsc+x4NundwoSzxjBsyI4sy2Wcdu6V3DFjNn023YSfnns8A9q2pmNZcsPt9/HZ71xb58MScMvNN3HaqZ+io6ODseM+yulnnFn3SE1TaQwi4hDg20AL8MPMHF/l9prlx5Pv5oLLbuOHX/rwinUfOvO/V1wef+qRPLPkOQDGvXckACOO+SrbbLU5v5hwEvt+8DwAvvU/v+L26bPZpHcLN174SQ4eOYRb7nqgiY9EXXV0dPDpU07m+htvpV9bG/vuM4JRo0bzxiFD6h6tKSo7TIiIFuB7wKHAEGBMRGwQ39W77nmEp5/5+yqv/5eDhnH5TTMAGDzg9fx66sMALPzLEp5Z/Bx7DdmR5/7xPLdPnw3A8y908PuHHqPftltWPrtWbdrUqQwcuDP9BwygtbWVo993LNdNvqbusZqmynMGbwHmZOajmbkUuBQ4osLtrRNGDhvIE08v5pE/LQTgvlntHH7Am2hp6cUbtn8dew7ZgbbXb/WSr9li8z68e/83rYiG6rFgQTttbTusWO7Xr4329vYaJ2quKg8T+gGPdVmeD+y98o0i4kTgRAA22bzCcZrjmEOGc8VN01csT7pmCoP7b8ddPz2DPz3+NHffO5cXOjpWXN/S0otJ48dy/iW/YV77U3WMrCIzX7YuImqYpB5VxqC77+LLvtuZORGYCNBrs21f/tNYj7S09OKIA9/MyPefu2JdR8cyzvjGVSuWf33xqcwpew0A3ztrDI/8aSETfvabZo6qbvTr18b8+S/+/mpvn8/2229f40TNVeVhwnxghy7LbcCCCrdXuwP3HsSseU/Q/uRfV6zrs+kmbLZpa7l+MC90LOOhR/8MwNknjWKLvn047bwr6xhXKxk+YgRz5sxm3ty5LF26lCsuu5TDRo2ue6ymqXLPYBqwS0T0B9qBY4H3V7i9ppl0zlj222sXtt5yc+bc9CW+dMENTPrFFI5+114rThwut81WfZl8/sksW5YsWPhXjj9rEgD9tt2SM084hIce/TNTLvkMABdcdhsXXz2l6Y9HnXr37s03vz2Bww97Fx0dHRw3dhxDhg6te6ymie6Ok9banUe8G/gWnX9avCgzv9LT7Xtttm2+atAxlc2jte8v0ybUPYLWwMi9hzNjxvRuT4RU+jyDzLwBuKHKbUhaO3w6siTAGEgqjIEkwBhIKoyBJMAYSCqMgSTAGEgqjIEkwBhIKoyBJMAYSCqMgSTAGEgqjIEkwBhIKoyBJMAYSCqMgSTAGEgqjIEkwBhIKoyBJMAYSCqMgSTAGEgqjIEkoIfPWoyIxcDyT2Vd/kGNWS5nZr6m4tkkNdEqY5CZfZs5iKR6NXSYEBH7RsRHyuWtI6J/tWNJarbVxiAizgY+A/xHWdUK/KTKoSQ1XyN7BkcCo4G/AWTmAsBDCGkD00gMlmZmUk4mRsSrqx1JUh0aicHlEXEhsGVEnAD8EvhBtWNJarZV/jVhucz8ekQcBDwL7Ap8LjNvrXwySU212hgU9wF96DxUuK+6cSTVpZG/JnwUmAq8FzgKuDsixlU9mKTmamTP4HRgz8x8CiAiXgf8L3BRlYNJaq5GTiDOBxZ3WV4MPFbNOJLq0tNrE04tF9uB30bENXSeMziCzsMGSRuQng4Tlj+x6JHyb7lrqhtHUl16eqHSF5o5iKR6rfYEYkRsA5wBDAU2Xb4+Mw+scC5JTdbICcSfAg8B/YEvAPOAaRXOJKkGjcTgdZn5I+D5zLwtM8cB+1Q8l6Qma+R5Bs+X/x+PiMOABUBbdSNJqkMjMfhyRGwB/DvwXeA1wL9VOpWkpmvkhUrXlYvPAG+vdhxJdenpSUff5cU3RH2ZzDxlbQ+zxxt35M4p313bdyupAT3tGUxv2hSSatfTk44mNXMQSfXyQ1QkAcZAUmEMJAGNvdPRrhHxq4i4vyzvHhFnVT+apGZqZM/gB3R+gMrzAJk5Ezi2yqEkNV8jMdgsM1d+M5MXqhhGUn0aicGiiBjIix+ichTweKVTSWq6Rl6bcDIwERgcEe3AXOCDlU4lqekaeW3Co8A7y8eq9crMxav7Gknrn0be6ehzKy0DkJlfrGgmSTVo5DDhb10ubwqMAh6sZhxJdWnkMOEbXZcj4uvAtZVNJKkWr+QZiJsBA9b2IJLq1cg5g/t48X0NWoBtAM8XSBuYRs4ZjOpy+QXgicz0SUfSBqbHGEREL+D6zNytSfNIqkmP5wwycxlwb0Ts2KR5JNWkkcOEfwL+EBFT6fJnxswcXdlUkpqukRj4mYvSRqCRGLw7Mz/TdUVEfA24rZqRJNWhkecZHNTNukPX9iCS6tXT5yZ8AjgJGBARM7tc1Re4q+rBJDVXT4cJPwNuBM4BzuyyfnFmPl3pVJKarqfPTXiGzo9UG9O8cSTVxXdHlgQYA0mFMZAEGANJhTGQBBgDSYUxkAQYA0mFMZAEGANJhTGQBBgDSYUxkAQYA0mFMZAEGANJhTGQBBgDSYUxkAQYA0mFMZAEGANJhTGQBBiDte7jJ47jDW3bMXzPN61YN3Pmvbx9/7cyYtjuHHXkaJ599tkaJ1RPbrn5JnYfOoihg3fmvHPH1z1OU1UWg4i4KCKejIj7q9rGuuiDHxrLLybf+JJ1J3/8BL745XOYds9MDj/iPXzrv86raTr1pKOjg0+fcjLXTL6R3818gCsuvYQHH3ig7rGapso9g4uBQyq8/3XSvvvtz2u3eu1L1s2e9TD77rc/AO94x0Fcc/VVdYym1Zg2dSoDB+5M/wEDaG1t5ej3Hct1k6+pe6ymqSwGmXk74GcyAkOG7sb1k68F4Korr2D+/MdqnkjdWbCgnba2HVYs9+vXRnt7e40TNVft5wwi4sSImB4R0xctWlj3OJX4/oU/4sILzmfkPsNZsmQxra2tdY+kbmTmy9ZFRA2T1KOnT2FuisycCEwEGLbX8Jf/NDYAgwYPZvINNwMwe9YsbrrxhponUnf69Wt7yV5be/t8tt9++xonaq7a9ww2Bk8++SQAy5Yt42vjv8LxJ3ys5onUneEjRjBnzmzmzZ3L0qVLueKySzls1Oi6x2qa2vcMNjTHfej93HH7b3hq0SJ2GbADZ3328yxZsoSJF5wPwOj3HMmHj/tIzVOqO7179+ab357A4Ye9i46ODo4bO44hQ4fWPVbTRHfHSWvljiMuAQ4AtgaeAM7OzB/19DXD9hqed06ZVsk8qkavXhvPMfWGYOTew5kxY3q3P7TK9gwyc0xV9y1p7fOcgSTAGEgqjIEkwBhIKoyBJMAYSCqMgSTAGEgqjIEkwBhIKoyBJMAYSCqMgSTAGEgqjIEkwBhIKoyBJMAYSCqMgSTAGEgqjIEkwBhIKoyBJMAYSCqMgSTAGEgqjIEkwBhIKoyBJMAYSCqMgSTAGEgqjIEkwBhIKoyBJMAYSCqMgSTAGEgqjIEkwBhIKoyBJMAYSCqMgSTAGEgqjIEkwBhIKoyBJMAYSCqMgSQAIjPrnmGFiFgI/LHuOSqwNbCo7iG0RjbUn9kbMnOb7q5Yp2KwoYqI6Zk5vO451LiN8WfmYYIkwBhIKoxBc0ysewCtsY3uZ+Y5A0mAewaSCmMgCTAGlYqIQyLi4YiYExFn1j2PVi8iLoqIJyPi/rpnaTZjUJGIaAG+BxwKDAHGRMSQeqdSAy4GDql7iDoYg+q8BZiTmY9m5lLgUuCImmfSamTm7cDTdc9RB2NQnX7AY12W55d10jrJGFQnulnn33G1zjIG1ZkP7NBluQ1YUNMs0moZg+pMA3aJiP4R0QocC1xb80zSKhmDimTmC8C/AjcDDwKXZ+Yf6p1KqxMRlwBTgEERMT8ijq97pmbx6ciSAPcMJBXGQBJgDCQVxkASYAwkFcZgIxURB0TEdeXy6J5eVRkRW0bESa9gG5+PiNMaXb/SbS6OiKPWYFs7bYyvNFybjMEGprxaco1k5rWZOb6Hm2wJrHEMtH4xBuuJ8pvvoYiYFBEzI+LnEbFZuW5eRHwuIu4Ejo6IgyNiSkTcExFXRMTm5XaHlPu4E3hvl/seGxETyuXtIuLqiLi3/HsrMB4YGBG/j4jzyu1Oj4hpZZYvdLmv/yzv4fBLYFADj+uEcj/3RsSVyx9T8c6IuCMiZkXEqHL7log4r8u2P/b//d6qkzFYvwwCJmbm7sCzvPS39T8yc1/gl8BZwDszcxgwHTg1IjYFfgAcDuwHvH4V2/gOcFtmvhkYBvwBOBN4JDP3yMzTI+JgYBc6X6a9B7BXROwfEXvR+bTrPemMzYgGHtNVmTmibO9BoOsz/nYC3gYcBlxQHsPxwDOZOaLc/wkR0b+B7Wg1etc9gNbIY5l5V7n8E+AU4Otl+bLy/z50vpnKXREB0Ern02sHA3MzczZARPwEOLGbbRwIfBggMzuAZyJiq5Vuc3D597uyvDmdcegLXJ2Zfy/baOS1GLtFxJfpPBTZnM6nby93eWYuA2ZHxKPlMRwM7N7lfMIWZduzGtiWemAM1i8rP3e86/Lfyv8B3JqZY7reMCL26ObrX6kAzsnMC1faxqdfwTYuBt6TmfdGxFjggC7Xdfd4A/hkZnaNBhGx0xpuVyvxMGH9smNE/HO5PAa4s5vb3A2MjIidASJis4jYFXgI6B8RA7t8fXd+BXyifG1LRLwGWEznb/3lbgbGdTkX0S8itgVuB46MiD4R0ZfOQ5LV6Qs8HhGbAB9Y6bqjI6JXmXkA8HDZ9ifK7YmIXSPi1Q1sR6thDNYvDwLHRcRM4LXA91e+QWYuBMYCl5Tb3Q0Mzsx/0HlYcH05gbiqD7j9FPD2iLgPmAEMzcyn6DzsuD8izsvMW4CfAVPK7X4O9M3Me+g8XPk9cCVwRwOP6bPAb4Fb6QxWVw8DtwE3Ah8vj+GHwAPAPeVPiRfiHu5a4asW1xNlN/i6zNyt7lm0YXLPQBLgnoGkwj0DSYAxkFQYA0mAMZBUGANJAPwfhiPBdPDP6NIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predictions)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I tried using class weights, in this case an incorrect guess on a Jordan paper is penalized 99x more harshly than on another paper. Everything else is exactly the same as the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {0:1, 1:99}\n",
    "lr2 = LogisticRegression(random_state=21, class_weight=weights)\n",
    "lr2.fit(X_train, y_train)\n",
    "predictions2 = lr2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the model scoring methods, I can see that this model is slightly better than the previous one, but not amazing by any means. 3/17 papers he wrote were sucessfully predicted, along with 41 false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9685256764218664\n",
      "AUC: 0.5675076362781956\n",
      "Recall score: 0.15789473684210525\n"
     ]
    }
   ],
   "source": [
    "accuracy2 = lr2.score(X_test, y_test)\n",
    "auc2 = roc_auc_score(y_test, predictions2)\n",
    "recall2 = recall_score(y_test, predictions2)\n",
    "print('Accuracy:', accuracy2)\n",
    "print('AUC:', auc2)\n",
    "print('Recall score:', recall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm2 = confusion_matrix(y_test, predictions2)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, I was curious to see if I was overfitting, so I repeated the above test but predicted on the train data instead of the test data. IM STILL NOT SURE IF THiS MEANS I AM OVERFITTING OR NOT, BUT THE SCORES HERE ARE INCREDIBLY HIGH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2_train = lr2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9825046040515654\n",
      "AUC: 0.9911545623836127\n",
      "Recall score: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy2_train = lr2.score(X_train, y_train)\n",
    "auc2_train = roc_auc_score(y_train, predictions2_train)\n",
    "recall2_train = recall_score(y_train, predictions2_train)\n",
    "print('Accuracy:', accuracy2_train)\n",
    "print('AUC:', auc2_train)\n",
    "print('Recall score:', recall2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm2_train = confusion_matrix(y_train, predictions2_train)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm2_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I wanted to try oversampling and undersampling as methods. I created a new train/test split so that I could oversample or undersample it accordingly. This is the \"oversample\" split, with the same random state as the last split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over, X_test_over, y_train_over, y_test_over = \\\n",
    "    train_test_split(X, y, random_state=21, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the actual oversampling. I only oversample the train set, and leave the test set as it was. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(random_state=21)\n",
    "\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again TfidfVectorizing the data, the shapes indicate that our train set now has 10,740 papers in it, with many being duplicates of Jordan's papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10740, 4854)\n",
      "(1811, 4854)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_over = tfidf.fit_transform(X_train_over.title)\n",
    "X_test_over = tfidf.transform(X_test_over.title)\n",
    "\n",
    "print(X_train_over.shape)\n",
    "print(X_test_over.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fitting the Logistic regression model to it, then predicting on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_over = LogisticRegression(random_state=21)\n",
    "lr_over.fit(X_train_over, y_train_over)\n",
    "predictions_over = lr_over.predict(X_test_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's scores show some improvement over the weighted example, but not by a ton and possibly explained by random variance. I will need to cross validate later to determine if one method is truly better than another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9707344008834898\n",
      "AUC: 0.5946604793233083\n",
      "Recall score: 0.21052631578947367\n"
     ]
    }
   ],
   "source": [
    "accuracy_over = lr_over.score(X_test_over, y_test_over)\n",
    "auc_over = roc_auc_score(y_test_over, predictions_over)\n",
    "recall_over = recall_score(y_test_over, predictions_over)\n",
    "print('Accuracy:', accuracy_over)\n",
    "print('AUC:', auc_over)\n",
    "print('Recall score:', recall_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time it was able to predict one additional paper, and with fewer false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_over = confusion_matrix(y_test_over, predictions_over)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm_over)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the undersampling split, again with the same random state as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_under, X_test_under, y_train_under, y_test_under = \\\n",
    "    train_test_split(X, y, random_state=21, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again only undersampling on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(random_state=21)\n",
    "\n",
    "X_train_under, y_train_under = undersample.fit_resample(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizing the titles, the shapes indicate that only 120 papers remain in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 461)\n",
      "(1811, 461)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_under = tfidf.fit_transform(X_train_under.title)\n",
    "X_test_under = tfidf.transform(X_test_under.title)\n",
    "\n",
    "print(X_train_under.shape)\n",
    "print(X_test_under.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the LogisticRegression model to the undersampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_under = LogisticRegression(random_state=21)\n",
    "lr_under.fit(X_train_under, y_train_under)\n",
    "predictions_under = lr_under.predict(X_test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores here show a marked difference to the previous ones. The accuracy has tanked, while recall score has gone way up to over 50%. The overall AUC remains around the same as the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5621203754831585\n",
      "AUC: 0.5704446663533834\n",
      "Recall score: 0.5789473684210527\n"
     ]
    }
   ],
   "source": [
    "accuracy_under = lr_under.score(X_test_under, y_test_under)\n",
    "auc_under = roc_auc_score(y_test_under, predictions_under)\n",
    "recall_under = recall_score(y_test_under, predictions_under)\n",
    "print('Accuracy:', accuracy_under)\n",
    "print('AUC:', auc_under)\n",
    "print('Recall score:', recall_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix indicates that there are now a huge number of false positives, only 20% smaller than the true negatives. The model was able to predict 8/19 of his papers, but overall this seems like a step back, and it's possible I did something incorrectly while undersampling the data. Or undersampling is just not an appropriate method for this type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_under = confusion_matrix(y_test_under, predictions_under)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm_under)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with more balanced test set, THIS IS NOT COMPLETED BUT IT\"S CLEAR I SHOULD HAVE USED the STRATIFY PARAMETER IN ORDER TO ENSURE THE PROPER BALANCE OF JORDAN PAPERS IN THE TRAIN AND TEST SETS. IN THIS CASE IT ADDED AN ADDITIONAL JORDAN PAPER TO THE TEST SET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X, y, random_state=21, train_size=0.75, stratify=y)\n",
    "\n",
    "print(y_test_t.tolist().count(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Springboard_Capstone_1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "918dc82fcda072602f7dedc1715dd52bd51c73a6bbc48592bc491021bad55eb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
